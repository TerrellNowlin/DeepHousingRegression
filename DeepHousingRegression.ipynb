{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing = keras.datasets.boston_housing\n",
    "\n",
    "(train_data,train_labels), (test_data,test_labels)=boston_housing.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=np.argsort(np.random.random(train_labels.shape))\n",
    "train_data=train_data[order]\n",
    "train_labels=train_labels[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.07875</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.782</td>\n",
       "      <td>41.1</td>\n",
       "      <td>3.7886</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>393.87</td>\n",
       "      <td>6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.55587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718</td>\n",
       "      <td>3.561</td>\n",
       "      <td>87.9</td>\n",
       "      <td>1.6132</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>354.70</td>\n",
       "      <td>7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09604</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.854</td>\n",
       "      <td>42.8</td>\n",
       "      <td>4.2673</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01870</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>6.516</td>\n",
       "      <td>27.7</td>\n",
       "      <td>8.5353</td>\n",
       "      <td>4.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>392.43</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.52693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504</td>\n",
       "      <td>8.725</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.8944</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>382.00</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.37857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.871</td>\n",
       "      <td>41.9</td>\n",
       "      <td>3.7240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>370.73</td>\n",
       "      <td>13.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.13642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>5.891</td>\n",
       "      <td>22.3</td>\n",
       "      <td>3.9454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.06888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>6.144</td>\n",
       "      <td>62.2</td>\n",
       "      <td>2.5979</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.13262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>5.851</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1069</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>394.05</td>\n",
       "      <td>16.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.60910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>7.313</td>\n",
       "      <td>97.9</td>\n",
       "      <td>1.3163</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.75026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.924</td>\n",
       "      <td>94.1</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.33</td>\n",
       "      <td>16.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01381</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>7.875</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.6484</td>\n",
       "      <td>4.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>394.23</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.65665</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>6.842</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>391.93</td>\n",
       "      <td>6.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.87205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>6.405</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.6768</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.24103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>6.083</td>\n",
       "      <td>43.7</td>\n",
       "      <td>5.4159</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.11432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>6.781</td>\n",
       "      <td>71.3</td>\n",
       "      <td>2.8561</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>395.58</td>\n",
       "      <td>7.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.86030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679</td>\n",
       "      <td>5.896</td>\n",
       "      <td>95.4</td>\n",
       "      <td>1.9096</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>7.68</td>\n",
       "      <td>24.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.31827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.2</td>\n",
       "      <td>3.9986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>390.70</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.38735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.613</td>\n",
       "      <td>95.6</td>\n",
       "      <td>1.7572</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>359.29</td>\n",
       "      <td>27.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.14476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>5.731</td>\n",
       "      <td>65.2</td>\n",
       "      <td>2.7592</td>\n",
       "      <td>6.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>391.50</td>\n",
       "      <td>13.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.02899</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>6.939</td>\n",
       "      <td>34.5</td>\n",
       "      <td>8.7921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>389.85</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.05561</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>7.041</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.8278</td>\n",
       "      <td>5.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>371.58</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.09740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.468</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4118</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>26.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.14932</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>5.741</td>\n",
       "      <td>66.2</td>\n",
       "      <td>7.2254</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>395.11</td>\n",
       "      <td>13.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.03445</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>6.162</td>\n",
       "      <td>38.4</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>393.77</td>\n",
       "      <td>7.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.82349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>6.794</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.3580</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.67202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>5.747</td>\n",
       "      <td>98.9</td>\n",
       "      <td>1.6334</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.10</td>\n",
       "      <td>19.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.03932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>6.405</td>\n",
       "      <td>73.9</td>\n",
       "      <td>3.0921</td>\n",
       "      <td>2.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>393.55</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2.30040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>6.319</td>\n",
       "      <td>96.1</td>\n",
       "      <td>2.1000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>297.09</td>\n",
       "      <td>11.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>11.08740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718</td>\n",
       "      <td>6.411</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.8589</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>318.75</td>\n",
       "      <td>15.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.34940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.972</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.1025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.24</td>\n",
       "      <td>9.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.14231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>6.254</td>\n",
       "      <td>84.2</td>\n",
       "      <td>2.2565</td>\n",
       "      <td>6.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>388.74</td>\n",
       "      <td>10.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1.38799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.950</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.9900</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>232.60</td>\n",
       "      <td>27.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>9.23230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>6.216</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.1691</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>366.15</td>\n",
       "      <td>9.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.08664</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>7.178</td>\n",
       "      <td>26.3</td>\n",
       "      <td>6.4798</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.49</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.67191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>90.3</td>\n",
       "      <td>4.6820</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.88</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.10793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>6.195</td>\n",
       "      <td>54.4</td>\n",
       "      <td>2.7778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>393.49</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.03150</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>6.975</td>\n",
       "      <td>15.3</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.05372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.549</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.9604</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>392.85</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2.44953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>6.402</td>\n",
       "      <td>95.2</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>330.04</td>\n",
       "      <td>11.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>3.16360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>5.759</td>\n",
       "      <td>48.2</td>\n",
       "      <td>3.0665</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>334.40</td>\n",
       "      <td>14.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.09065</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464</td>\n",
       "      <td>5.920</td>\n",
       "      <td>61.5</td>\n",
       "      <td>3.9175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>391.34</td>\n",
       "      <td>13.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>12.80230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>5.854</td>\n",
       "      <td>96.6</td>\n",
       "      <td>1.8956</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>240.52</td>\n",
       "      <td>23.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.43571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489</td>\n",
       "      <td>5.344</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>23.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.14866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>6.727</td>\n",
       "      <td>79.9</td>\n",
       "      <td>2.7778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>394.76</td>\n",
       "      <td>9.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.81838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>5.762</td>\n",
       "      <td>40.3</td>\n",
       "      <td>4.0983</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.92</td>\n",
       "      <td>10.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.01432</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>6.816</td>\n",
       "      <td>40.5</td>\n",
       "      <td>8.3248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>392.90</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>6.80117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.081</td>\n",
       "      <td>84.4</td>\n",
       "      <td>2.7175</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.25387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>5.399</td>\n",
       "      <td>95.3</td>\n",
       "      <td>5.8700</td>\n",
       "      <td>3.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>396.90</td>\n",
       "      <td>30.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>6.96215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>5.713</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.9265</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>394.43</td>\n",
       "      <td>17.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>3.77498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>5.952</td>\n",
       "      <td>84.7</td>\n",
       "      <td>2.8715</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.01</td>\n",
       "      <td>17.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.40771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>6.164</td>\n",
       "      <td>91.3</td>\n",
       "      <td>3.0480</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>395.24</td>\n",
       "      <td>21.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.546</td>\n",
       "      <td>33.1</td>\n",
       "      <td>3.1323</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>390.96</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>7.02259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718</td>\n",
       "      <td>6.006</td>\n",
       "      <td>95.3</td>\n",
       "      <td>1.8746</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>319.98</td>\n",
       "      <td>15.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2    3      4      5      6       7     8      9   \\\n",
       "0     0.07875   45.0   3.44  0.0  0.437  6.782   41.1  3.7886   5.0  398.0   \n",
       "1     4.55587    0.0  18.10  0.0  0.718  3.561   87.9  1.6132  24.0  666.0   \n",
       "2     0.09604   40.0   6.41  0.0  0.447  6.854   42.8  4.2673   4.0  254.0   \n",
       "3     0.01870   85.0   4.15  0.0  0.429  6.516   27.7  8.5353   4.0  351.0   \n",
       "4     0.52693    0.0   6.20  0.0  0.504  8.725   83.0  2.8944   8.0  307.0   \n",
       "5     2.37857    0.0  18.10  0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
       "6     0.13642    0.0  10.59  0.0  0.489  5.891   22.3  3.9454   4.0  277.0   \n",
       "7     0.06888    0.0   2.46  0.0  0.488  6.144   62.2  2.5979   3.0  193.0   \n",
       "8     0.17331    0.0   9.69  0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
       "9     0.13262    0.0   8.56  0.0  0.520  5.851   96.7  2.1069   5.0  384.0   \n",
       "10   19.60910    0.0  18.10  0.0  0.671  7.313   97.9  1.3163  24.0  666.0   \n",
       "11    0.75026    0.0   8.14  0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
       "12    0.01381   80.0   0.46  0.0  0.422  7.875   32.0  5.6484   4.0  255.0   \n",
       "13    0.65665   20.0   3.97  0.0  0.647  6.842  100.0  2.0107   5.0  264.0   \n",
       "14    5.87205    0.0  18.10  0.0  0.693  6.405   96.0  1.6768  24.0  666.0   \n",
       "15    0.24103    0.0   7.38  0.0  0.493  6.083   43.7  5.4159   5.0  287.0   \n",
       "16    0.11432    0.0   8.56  0.0  0.520  6.781   71.3  2.8561   5.0  384.0   \n",
       "17    4.89822    0.0  18.10  0.0  0.631  4.970  100.0  1.3325  24.0  666.0   \n",
       "18   15.86030    0.0  18.10  0.0  0.679  5.896   95.4  1.9096  24.0  666.0   \n",
       "19    0.21124   12.5   7.87  0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
       "20    0.31827    0.0   9.90  0.0  0.544  5.914   83.2  3.9986   4.0  304.0   \n",
       "21    0.38735    0.0  25.65  0.0  0.581  5.613   95.6  1.7572   2.0  188.0   \n",
       "22    0.14476    0.0  10.01  0.0  0.547  5.731   65.2  2.7592   6.0  432.0   \n",
       "23    0.02899   40.0   1.25  0.0  0.429  6.939   34.5  8.7921   1.0  335.0   \n",
       "24    0.05561   70.0   2.24  0.0  0.400  7.041   10.0  7.8278   5.0  358.0   \n",
       "25    4.09740    0.0  19.58  0.0  0.871  5.468  100.0  1.4118   5.0  403.0   \n",
       "26    0.14932   25.0   5.13  0.0  0.453  5.741   66.2  7.2254   8.0  284.0   \n",
       "27    0.03445   82.5   2.03  0.0  0.415  6.162   38.4  6.2700   2.0  348.0   \n",
       "28    9.82349    0.0  18.10  0.0  0.671  6.794   98.8  1.3580  24.0  666.0   \n",
       "29    7.67202    0.0  18.10  0.0  0.693  5.747   98.9  1.6334  24.0  666.0   \n",
       "..        ...    ...    ...  ...    ...    ...    ...     ...   ...    ...   \n",
       "374   0.03932    0.0   3.41  0.0  0.489  6.405   73.9  3.0921   2.0  270.0   \n",
       "375   2.30040    0.0  19.58  0.0  0.605  6.319   96.1  2.1000   5.0  403.0   \n",
       "376  11.08740    0.0  18.10  0.0  0.718  6.411  100.0  1.8589  24.0  666.0   \n",
       "377   0.34940    0.0   9.90  0.0  0.544  5.972   76.7  3.1025   4.0  304.0   \n",
       "378   0.14231    0.0  10.01  0.0  0.547  6.254   84.2  2.2565   6.0  432.0   \n",
       "379   1.38799    0.0   8.14  0.0  0.538  5.950   82.0  3.9900   4.0  307.0   \n",
       "380   9.23230    0.0  18.10  0.0  0.631  6.216  100.0  1.1691  24.0  666.0   \n",
       "381   0.08664   45.0   3.44  0.0  0.437  7.178   26.3  6.4798   5.0  398.0   \n",
       "382   0.67191    0.0   8.14  0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
       "383   0.10793    0.0   8.56  0.0  0.520  6.195   54.4  2.7778   5.0  384.0   \n",
       "384   0.78420    0.0   8.14  0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
       "385   0.03150   95.0   1.47  0.0  0.403  6.975   15.3  7.6534   3.0  402.0   \n",
       "386   0.09164    0.0  10.81  0.0  0.413  6.065    7.8  5.2873   4.0  305.0   \n",
       "387   0.05372    0.0  13.92  0.0  0.437  6.549   51.0  5.9604   4.0  289.0   \n",
       "388   2.44953    0.0  19.58  0.0  0.605  6.402   95.2  2.2625   5.0  403.0   \n",
       "389   3.69311    0.0  18.10  0.0  0.713  6.376   88.4  2.5671  24.0  666.0   \n",
       "390   3.16360    0.0  18.10  0.0  0.655  5.759   48.2  3.0665  24.0  666.0   \n",
       "391   0.09065   20.0   6.96  1.0  0.464  5.920   61.5  3.9175   3.0  223.0   \n",
       "392  12.80230    0.0  18.10  0.0  0.740  5.854   96.6  1.8956  24.0  666.0   \n",
       "393   0.43571    0.0  10.59  1.0  0.489  5.344  100.0  3.8750   4.0  277.0   \n",
       "394   0.14866    0.0   8.56  0.0  0.520  6.727   79.9  2.7778   5.0  384.0   \n",
       "395   2.81838    0.0  18.10  0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
       "396   0.01432  100.0   1.32  0.0  0.411  6.816   40.5  8.3248   5.0  256.0   \n",
       "397   6.80117    0.0  18.10  0.0  0.713  6.081   84.4  2.7175  24.0  666.0   \n",
       "398   0.25387    0.0   6.91  0.0  0.448  5.399   95.3  5.8700   3.0  233.0   \n",
       "399   6.96215    0.0  18.10  0.0  0.700  5.713   97.0  1.9265  24.0  666.0   \n",
       "400   3.77498    0.0  18.10  0.0  0.655  5.952   84.7  2.8715  24.0  666.0   \n",
       "401   0.40771    0.0   6.20  1.0  0.507  6.164   91.3  3.0480   8.0  307.0   \n",
       "402   0.06664    0.0   4.05  0.0  0.510  6.546   33.1  3.1323   5.0  296.0   \n",
       "403   7.02259    0.0  18.10  0.0  0.718  6.006   95.3  1.8746  24.0  666.0   \n",
       "\n",
       "       10      11     12  \n",
       "0    15.2  393.87   6.68  \n",
       "1    20.2  354.70   7.12  \n",
       "2    17.6  396.90   2.98  \n",
       "3    17.9  392.43   6.36  \n",
       "4    17.4  382.00   4.63  \n",
       "5    20.2  370.73  13.34  \n",
       "6    18.6  396.90  10.87  \n",
       "7    17.8  396.90   9.45  \n",
       "8    19.2  396.90  12.01  \n",
       "9    20.9  394.05  16.47  \n",
       "10   20.2  396.90  13.44  \n",
       "11   21.0  394.33  16.30  \n",
       "12   14.4  394.23   2.97  \n",
       "13   13.0  391.93   6.90  \n",
       "14   20.2  396.90  19.37  \n",
       "15   19.6  396.90  12.79  \n",
       "16   20.9  395.58   7.67  \n",
       "17   20.2  375.52   3.26  \n",
       "18   20.2    7.68  24.39  \n",
       "19   15.2  386.63  29.93  \n",
       "20   18.4  390.70  18.33  \n",
       "21   19.1  359.29  27.26  \n",
       "22   17.8  391.50  13.61  \n",
       "23   19.7  389.85   5.89  \n",
       "24   14.8  371.58   4.74  \n",
       "25   14.7  396.90  26.42  \n",
       "26   19.7  395.11  13.15  \n",
       "27   14.7  393.77   7.43  \n",
       "28   20.2  396.90  21.24  \n",
       "29   20.2  393.10  19.92  \n",
       "..    ...     ...    ...  \n",
       "374  17.8  393.55   8.20  \n",
       "375  14.7  297.09  11.10  \n",
       "376  20.2  318.75  15.02  \n",
       "377  18.4  396.24   9.97  \n",
       "378  17.8  388.74  10.45  \n",
       "379  21.0  232.60  27.71  \n",
       "380  20.2  366.15   9.53  \n",
       "381  15.2  390.49   2.87  \n",
       "382  21.0  376.88  14.81  \n",
       "383  20.9  393.49  13.00  \n",
       "384  21.0  386.75  14.67  \n",
       "385  17.0  396.90   4.56  \n",
       "386  19.2  390.91   5.52  \n",
       "387  16.0  392.85   7.39  \n",
       "388  14.7  330.04  11.32  \n",
       "389  20.2  391.43  14.65  \n",
       "390  20.2  334.40  14.13  \n",
       "391  18.6  391.34  13.65  \n",
       "392  20.2  240.52  23.79  \n",
       "393  18.6  396.90  23.09  \n",
       "394  20.9  394.76   9.42  \n",
       "395  20.2  392.92  10.42  \n",
       "396  15.1  392.90   3.95  \n",
       "397  20.2  396.90  14.70  \n",
       "398  17.9  396.90  30.81  \n",
       "399  20.2  394.43  17.11  \n",
       "400  20.2   22.01  17.15  \n",
       "401  17.4  395.24  21.46  \n",
       "402  16.6  390.96   5.33  \n",
       "403  20.2  319.98  15.70  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean=train_data.mean(axis=0)\n",
    "std=train_data.std(axis=0)\n",
    "train_data=(train_data-mean)/std\n",
    "test_data=(test_data-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Build the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "[keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(train_data.shape[1],))\n",
    ",keras.layers.Dense(64, activation=tf.nn.relu)\n",
    ",keras.layers.Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/400\n",
      "323/323 [==============================] - 0s 1ms/step - loss: 546.8345 - mean_absolute_error: 21.5209 - val_loss: 567.0699 - val_mean_absolute_error: 22.0798\n",
      "Epoch 2/400\n",
      "323/323 [==============================] - 0s 125us/step - loss: 497.8956 - mean_absolute_error: 20.3771 - val_loss: 506.6168 - val_mean_absolute_error: 20.7382\n",
      "Epoch 3/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 437.9181 - mean_absolute_error: 18.8754 - val_loss: 431.9882 - val_mean_absolute_error: 18.9333\n",
      "Epoch 4/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 363.1962 - mean_absolute_error: 16.8408 - val_loss: 338.5502 - val_mean_absolute_error: 16.4369\n",
      "Epoch 5/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 272.6728 - mean_absolute_error: 14.2653 - val_loss: 232.7146 - val_mean_absolute_error: 13.1969\n",
      "Epoch 6/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 179.5597 - mean_absolute_error: 11.0296 - val_loss: 136.5029 - val_mean_absolute_error: 9.5921\n",
      "Epoch 7/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 108.1306 - mean_absolute_error: 8.2707 - val_loss: 79.1795 - val_mean_absolute_error: 6.9508\n",
      "Epoch 8/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 69.4904 - mean_absolute_error: 6.4682 - val_loss: 57.9072 - val_mean_absolute_error: 5.4840\n",
      "Epoch 9/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 53.4966 - mean_absolute_error: 5.5327 - val_loss: 46.5164 - val_mean_absolute_error: 4.7579\n",
      "Epoch 10/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 42.1325 - mean_absolute_error: 4.7820 - val_loss: 39.3324 - val_mean_absolute_error: 4.2874\n",
      "Epoch 11/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 34.2661 - mean_absolute_error: 4.2157 - val_loss: 35.2353 - val_mean_absolute_error: 4.0085\n",
      "Epoch 12/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 29.4494 - mean_absolute_error: 3.8281 - val_loss: 32.5723 - val_mean_absolute_error: 3.8195\n",
      "Epoch 13/400\n",
      "323/323 [==============================] - 0s 93us/step - loss: 26.4589 - mean_absolute_error: 3.5990 - val_loss: 31.2763 - val_mean_absolute_error: 3.7244\n",
      "Epoch 14/400\n",
      "323/323 [==============================] - 0s 102us/step - loss: 24.4606 - mean_absolute_error: 3.4499 - val_loss: 29.8733 - val_mean_absolute_error: 3.6629\n",
      "Epoch 15/400\n",
      "323/323 [==============================] - 0s 89us/step - loss: 22.9068 - mean_absolute_error: 3.3485 - val_loss: 29.0704 - val_mean_absolute_error: 3.6324\n",
      "Epoch 16/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 21.8552 - mean_absolute_error: 3.2927 - val_loss: 28.3189 - val_mean_absolute_error: 3.5841\n",
      "Epoch 17/400\n",
      "323/323 [==============================] - 0s 97us/step - loss: 20.7136 - mean_absolute_error: 3.1878 - val_loss: 27.9704 - val_mean_absolute_error: 3.5217\n",
      "Epoch 18/400\n",
      "323/323 [==============================] - 0s 90us/step - loss: 19.8813 - mean_absolute_error: 3.1010 - val_loss: 27.5575 - val_mean_absolute_error: 3.4745\n",
      "Epoch 19/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 19.0314 - mean_absolute_error: 3.0308 - val_loss: 26.7781 - val_mean_absolute_error: 3.4324\n",
      "Epoch 20/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 18.3536 - mean_absolute_error: 3.0302 - val_loss: 25.8201 - val_mean_absolute_error: 3.4004\n",
      "Epoch 21/400\n",
      "323/323 [==============================] - 0s 100us/step - loss: 17.9014 - mean_absolute_error: 3.0264 - val_loss: 24.5185 - val_mean_absolute_error: 3.3329\n",
      "Epoch 22/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 17.1193 - mean_absolute_error: 2.9493 - val_loss: 24.1716 - val_mean_absolute_error: 3.2726\n",
      "Epoch 23/400\n",
      "323/323 [==============================] - 0s 86us/step - loss: 16.3659 - mean_absolute_error: 2.8558 - val_loss: 24.0158 - val_mean_absolute_error: 3.2616\n",
      "Epoch 24/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 15.8114 - mean_absolute_error: 2.8139 - val_loss: 23.4807 - val_mean_absolute_error: 3.2124\n",
      "Epoch 25/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 15.4151 - mean_absolute_error: 2.7403 - val_loss: 23.1684 - val_mean_absolute_error: 3.1844\n",
      "Epoch 26/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 14.9678 - mean_absolute_error: 2.7125 - val_loss: 22.1892 - val_mean_absolute_error: 3.1072\n",
      "Epoch 27/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 14.4561 - mean_absolute_error: 2.6877 - val_loss: 22.0977 - val_mean_absolute_error: 3.1006\n",
      "Epoch 28/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 14.1078 - mean_absolute_error: 2.6577 - val_loss: 21.8909 - val_mean_absolute_error: 3.0957\n",
      "Epoch 29/400\n",
      "323/323 [==============================] - 0s 90us/step - loss: 13.7264 - mean_absolute_error: 2.6430 - val_loss: 21.2896 - val_mean_absolute_error: 3.0379\n",
      "Epoch 30/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 13.3891 - mean_absolute_error: 2.6030 - val_loss: 21.1122 - val_mean_absolute_error: 3.0199\n",
      "Epoch 31/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 13.0799 - mean_absolute_error: 2.5818 - val_loss: 21.0771 - val_mean_absolute_error: 3.0269\n",
      "Epoch 32/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 12.7268 - mean_absolute_error: 2.5310 - val_loss: 20.8603 - val_mean_absolute_error: 3.0115\n",
      "Epoch 33/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 12.5473 - mean_absolute_error: 2.5124 - val_loss: 20.6582 - val_mean_absolute_error: 3.0257\n",
      "Epoch 34/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 12.1946 - mean_absolute_error: 2.4973 - val_loss: 20.7226 - val_mean_absolute_error: 3.0495\n",
      "Epoch 35/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 11.9123 - mean_absolute_error: 2.4847 - val_loss: 20.3931 - val_mean_absolute_error: 3.0166\n",
      "Epoch 36/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 11.6798 - mean_absolute_error: 2.4830 - val_loss: 20.6079 - val_mean_absolute_error: 3.0731\n",
      "Epoch 37/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 11.4542 - mean_absolute_error: 2.4650 - val_loss: 20.2817 - val_mean_absolute_error: 3.0169\n",
      "Epoch 38/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 11.1492 - mean_absolute_error: 2.3956 - val_loss: 19.8125 - val_mean_absolute_error: 2.9591\n",
      "Epoch 39/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 11.1271 - mean_absolute_error: 2.3863 - val_loss: 19.4243 - val_mean_absolute_error: 2.9437\n",
      "Epoch 40/400\n",
      "323/323 [==============================] - 0s 66us/step - loss: 10.7371 - mean_absolute_error: 2.3797 - val_loss: 19.2697 - val_mean_absolute_error: 2.9608\n",
      "Epoch 41/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 10.5111 - mean_absolute_error: 2.3506 - val_loss: 19.0992 - val_mean_absolute_error: 2.9376\n",
      "Epoch 42/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 10.3947 - mean_absolute_error: 2.3172 - val_loss: 19.0208 - val_mean_absolute_error: 2.9283\n",
      "Epoch 43/400\n",
      "323/323 [==============================] - 0s 68us/step - loss: 10.2415 - mean_absolute_error: 2.2977 - val_loss: 18.9665 - val_mean_absolute_error: 2.9277\n",
      "Epoch 44/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 10.0281 - mean_absolute_error: 2.2764 - val_loss: 18.7701 - val_mean_absolute_error: 2.9223\n",
      "Epoch 45/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 9.7957 - mean_absolute_error: 2.2550 - val_loss: 18.3652 - val_mean_absolute_error: 2.8992\n",
      "Epoch 46/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 9.7026 - mean_absolute_error: 2.2525 - val_loss: 18.3345 - val_mean_absolute_error: 2.8827\n",
      "Epoch 47/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 9.6698 - mean_absolute_error: 2.2364 - val_loss: 18.6075 - val_mean_absolute_error: 2.9146\n",
      "Epoch 48/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 9.3879 - mean_absolute_error: 2.2190 - val_loss: 18.7062 - val_mean_absolute_error: 2.9469\n",
      "Epoch 49/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 82us/step - loss: 9.2839 - mean_absolute_error: 2.2061 - val_loss: 17.9587 - val_mean_absolute_error: 2.8841\n",
      "Epoch 50/400\n",
      "323/323 [==============================] - 0s 91us/step - loss: 9.1672 - mean_absolute_error: 2.1802 - val_loss: 17.8551 - val_mean_absolute_error: 2.8691\n",
      "Epoch 51/400\n",
      "323/323 [==============================] - 0s 138us/step - loss: 8.9934 - mean_absolute_error: 2.1754 - val_loss: 17.8298 - val_mean_absolute_error: 2.8872\n",
      "Epoch 52/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 9.0042 - mean_absolute_error: 2.1835 - val_loss: 17.4019 - val_mean_absolute_error: 2.8589\n",
      "Epoch 53/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 8.8996 - mean_absolute_error: 2.1595 - val_loss: 17.4730 - val_mean_absolute_error: 2.8361\n",
      "Epoch 54/400\n",
      "323/323 [==============================] - 0s 109us/step - loss: 8.7890 - mean_absolute_error: 2.1421 - val_loss: 17.5483 - val_mean_absolute_error: 2.8622\n",
      "Epoch 55/400\n",
      "323/323 [==============================] - 0s 105us/step - loss: 8.5554 - mean_absolute_error: 2.1313 - val_loss: 17.4767 - val_mean_absolute_error: 2.8721\n",
      "Epoch 56/400\n",
      "323/323 [==============================] - 0s 107us/step - loss: 8.5511 - mean_absolute_error: 2.1297 - val_loss: 17.5282 - val_mean_absolute_error: 2.8745\n",
      "Epoch 57/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 8.3753 - mean_absolute_error: 2.1023 - val_loss: 17.4011 - val_mean_absolute_error: 2.8598\n",
      "Epoch 58/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 8.3577 - mean_absolute_error: 2.0844 - val_loss: 17.8189 - val_mean_absolute_error: 2.8776\n",
      "Epoch 59/400\n",
      "323/323 [==============================] - 0s 110us/step - loss: 8.3470 - mean_absolute_error: 2.0790 - val_loss: 17.3268 - val_mean_absolute_error: 2.8432\n",
      "Epoch 60/400\n",
      "323/323 [==============================] - 0s 97us/step - loss: 8.1762 - mean_absolute_error: 2.0595 - val_loss: 16.7975 - val_mean_absolute_error: 2.8234\n",
      "Epoch 61/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 8.0795 - mean_absolute_error: 2.0677 - val_loss: 16.9007 - val_mean_absolute_error: 2.8564\n",
      "Epoch 62/400\n",
      "323/323 [==============================] - 0s 107us/step - loss: 8.0900 - mean_absolute_error: 2.0821 - val_loss: 17.1282 - val_mean_absolute_error: 2.8890\n",
      "Epoch 63/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 7.9807 - mean_absolute_error: 2.0668 - val_loss: 17.3875 - val_mean_absolute_error: 2.9132\n",
      "Epoch 64/400\n",
      "323/323 [==============================] - 0s 95us/step - loss: 7.8399 - mean_absolute_error: 2.0403 - val_loss: 17.2077 - val_mean_absolute_error: 2.8612\n",
      "Epoch 65/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 7.8461 - mean_absolute_error: 2.0388 - val_loss: 17.2388 - val_mean_absolute_error: 2.8876\n",
      "Epoch 66/400\n",
      "323/323 [==============================] - 0s 99us/step - loss: 7.7423 - mean_absolute_error: 2.0300 - val_loss: 17.1024 - val_mean_absolute_error: 2.8902\n",
      "Epoch 67/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 7.7931 - mean_absolute_error: 2.0325 - val_loss: 17.7209 - val_mean_absolute_error: 2.9458\n",
      "Epoch 68/400\n",
      "323/323 [==============================] - 0s 108us/step - loss: 7.8264 - mean_absolute_error: 2.0480 - val_loss: 17.2015 - val_mean_absolute_error: 2.9450\n",
      "Epoch 69/400\n",
      "323/323 [==============================] - 0s 110us/step - loss: 7.5683 - mean_absolute_error: 2.0240 - val_loss: 16.8686 - val_mean_absolute_error: 2.8951\n",
      "Epoch 70/400\n",
      "323/323 [==============================] - 0s 100us/step - loss: 7.6772 - mean_absolute_error: 2.0390 - val_loss: 16.7560 - val_mean_absolute_error: 2.8814\n",
      "Epoch 71/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 7.5923 - mean_absolute_error: 2.0283 - val_loss: 16.2477 - val_mean_absolute_error: 2.8272\n",
      "Epoch 72/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 7.4524 - mean_absolute_error: 2.0050 - val_loss: 16.2921 - val_mean_absolute_error: 2.8397\n",
      "Epoch 73/400\n",
      "323/323 [==============================] - 0s 86us/step - loss: 7.3391 - mean_absolute_error: 1.9778 - val_loss: 16.3993 - val_mean_absolute_error: 2.8246\n",
      "Epoch 74/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 7.3510 - mean_absolute_error: 1.9758 - val_loss: 16.7702 - val_mean_absolute_error: 2.8728\n",
      "Epoch 75/400\n",
      "323/323 [==============================] - 0s 89us/step - loss: 7.5098 - mean_absolute_error: 2.0297 - val_loss: 16.5351 - val_mean_absolute_error: 2.8389\n",
      "Epoch 76/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 7.3567 - mean_absolute_error: 1.9723 - val_loss: 16.5256 - val_mean_absolute_error: 2.8184\n",
      "Epoch 77/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 7.3522 - mean_absolute_error: 1.9862 - val_loss: 16.5935 - val_mean_absolute_error: 2.8543\n",
      "Epoch 78/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 7.1623 - mean_absolute_error: 1.9649 - val_loss: 16.2097 - val_mean_absolute_error: 2.8269\n",
      "Epoch 79/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 7.0224 - mean_absolute_error: 1.9437 - val_loss: 16.1931 - val_mean_absolute_error: 2.8345\n",
      "Epoch 80/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 7.0216 - mean_absolute_error: 1.9285 - val_loss: 16.3657 - val_mean_absolute_error: 2.8419\n",
      "Epoch 81/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 6.9312 - mean_absolute_error: 1.9234 - val_loss: 16.0966 - val_mean_absolute_error: 2.8255\n",
      "Epoch 82/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 6.9998 - mean_absolute_error: 1.9569 - val_loss: 16.2706 - val_mean_absolute_error: 2.8479\n",
      "Epoch 83/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 6.9327 - mean_absolute_error: 1.9491 - val_loss: 16.2650 - val_mean_absolute_error: 2.8412\n",
      "Epoch 84/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 6.8756 - mean_absolute_error: 1.9324 - val_loss: 15.8750 - val_mean_absolute_error: 2.8138\n",
      "Epoch 85/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 6.8091 - mean_absolute_error: 1.9130 - val_loss: 16.0262 - val_mean_absolute_error: 2.8303\n",
      "Epoch 86/400\n",
      "323/323 [==============================] - 0s 90us/step - loss: 6.7580 - mean_absolute_error: 1.9162 - val_loss: 15.8235 - val_mean_absolute_error: 2.7984\n",
      "Epoch 87/400\n",
      "323/323 [==============================] - 0s 95us/step - loss: 6.7774 - mean_absolute_error: 1.9155 - val_loss: 15.9690 - val_mean_absolute_error: 2.8153\n",
      "Epoch 88/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 6.7637 - mean_absolute_error: 1.9070 - val_loss: 15.9465 - val_mean_absolute_error: 2.8099\n",
      "Epoch 89/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 6.6275 - mean_absolute_error: 1.8806 - val_loss: 15.8356 - val_mean_absolute_error: 2.7910\n",
      "Epoch 90/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 6.8213 - mean_absolute_error: 1.9140 - val_loss: 16.1147 - val_mean_absolute_error: 2.8179\n",
      "Epoch 91/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 6.6384 - mean_absolute_error: 1.8852 - val_loss: 16.2588 - val_mean_absolute_error: 2.8344\n",
      "Epoch 92/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 6.5782 - mean_absolute_error: 1.8790 - val_loss: 15.7722 - val_mean_absolute_error: 2.7929\n",
      "Epoch 93/400\n",
      "323/323 [==============================] - 0s 96us/step - loss: 6.5372 - mean_absolute_error: 1.8824 - val_loss: 15.8859 - val_mean_absolute_error: 2.8201\n",
      "Epoch 94/400\n",
      "323/323 [==============================] - 0s 96us/step - loss: 6.4165 - mean_absolute_error: 1.8502 - val_loss: 16.0215 - val_mean_absolute_error: 2.8186\n",
      "Epoch 95/400\n",
      "323/323 [==============================] - 0s 98us/step - loss: 6.4867 - mean_absolute_error: 1.8537 - val_loss: 15.3783 - val_mean_absolute_error: 2.7322\n",
      "Epoch 96/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 6.5258 - mean_absolute_error: 1.8585 - val_loss: 15.1913 - val_mean_absolute_error: 2.7194\n",
      "Epoch 97/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 6.4405 - mean_absolute_error: 1.8710 - val_loss: 15.2452 - val_mean_absolute_error: 2.7526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 6.3427 - mean_absolute_error: 1.8531 - val_loss: 15.3909 - val_mean_absolute_error: 2.7614\n",
      "Epoch 99/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 6.2878 - mean_absolute_error: 1.8473 - val_loss: 15.5471 - val_mean_absolute_error: 2.7762\n",
      "Epoch 100/400\n",
      "323/323 [==============================] - 0s 90us/step - loss: 6.2440 - mean_absolute_error: 1.8302 - val_loss: 15.6096 - val_mean_absolute_error: 2.7713\n",
      "Epoch 101/400\n",
      "323/323 [==============================] - 0s 113us/step - loss: 6.1891 - mean_absolute_error: 1.8192 - val_loss: 15.5550 - val_mean_absolute_error: 2.7664\n",
      "Epoch 102/400\n",
      "323/323 [==============================] - 0s 110us/step - loss: 6.2058 - mean_absolute_error: 1.8126 - val_loss: 15.6480 - val_mean_absolute_error: 2.7779\n",
      "Epoch 103/400\n",
      "323/323 [==============================] - 0s 111us/step - loss: 6.2871 - mean_absolute_error: 1.8175 - val_loss: 15.6780 - val_mean_absolute_error: 2.7744\n",
      "Epoch 104/400\n",
      "323/323 [==============================] - 0s 104us/step - loss: 6.3149 - mean_absolute_error: 1.8404 - val_loss: 15.1530 - val_mean_absolute_error: 2.7305\n",
      "Epoch 105/400\n",
      "323/323 [==============================] - 0s 96us/step - loss: 6.2752 - mean_absolute_error: 1.8646 - val_loss: 15.5669 - val_mean_absolute_error: 2.7790\n",
      "Epoch 106/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 6.0372 - mean_absolute_error: 1.8083 - val_loss: 15.5389 - val_mean_absolute_error: 2.7646\n",
      "Epoch 107/400\n",
      "323/323 [==============================] - 0s 114us/step - loss: 6.0349 - mean_absolute_error: 1.7925 - val_loss: 15.5468 - val_mean_absolute_error: 2.7660\n",
      "Epoch 108/400\n",
      "323/323 [==============================] - 0s 105us/step - loss: 6.0139 - mean_absolute_error: 1.7947 - val_loss: 15.3524 - val_mean_absolute_error: 2.7292\n",
      "Epoch 109/400\n",
      "323/323 [==============================] - 0s 107us/step - loss: 5.9773 - mean_absolute_error: 1.7984 - val_loss: 15.3150 - val_mean_absolute_error: 2.7419\n",
      "Epoch 110/400\n",
      "323/323 [==============================] - 0s 91us/step - loss: 5.9299 - mean_absolute_error: 1.7901 - val_loss: 15.4011 - val_mean_absolute_error: 2.7414\n",
      "Epoch 111/400\n",
      "323/323 [==============================] - 0s 99us/step - loss: 5.8991 - mean_absolute_error: 1.7695 - val_loss: 15.4939 - val_mean_absolute_error: 2.7481\n",
      "Epoch 112/400\n",
      "323/323 [==============================] - 0s 115us/step - loss: 5.8976 - mean_absolute_error: 1.7774 - val_loss: 15.3135 - val_mean_absolute_error: 2.7241\n",
      "Epoch 113/400\n",
      "323/323 [==============================] - 0s 101us/step - loss: 5.8968 - mean_absolute_error: 1.7906 - val_loss: 15.2255 - val_mean_absolute_error: 2.7252\n",
      "Epoch 114/400\n",
      "323/323 [==============================] - 0s 100us/step - loss: 5.8585 - mean_absolute_error: 1.7843 - val_loss: 15.2582 - val_mean_absolute_error: 2.7415\n",
      "Epoch 115/400\n",
      "323/323 [==============================] - 0s 146us/step - loss: 5.9481 - mean_absolute_error: 1.7918 - val_loss: 15.5669 - val_mean_absolute_error: 2.7695\n",
      "Epoch 116/400\n",
      "323/323 [==============================] - 0s 91us/step - loss: 5.7926 - mean_absolute_error: 1.7735 - val_loss: 15.6936 - val_mean_absolute_error: 2.7886\n",
      "Epoch 117/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 5.7843 - mean_absolute_error: 1.7873 - val_loss: 15.5711 - val_mean_absolute_error: 2.7700\n",
      "Epoch 118/400\n",
      "323/323 [==============================] - 0s 108us/step - loss: 5.7295 - mean_absolute_error: 1.7786 - val_loss: 15.6244 - val_mean_absolute_error: 2.7927\n",
      "Epoch 119/400\n",
      "323/323 [==============================] - 0s 110us/step - loss: 5.6752 - mean_absolute_error: 1.7538 - val_loss: 15.3156 - val_mean_absolute_error: 2.7593\n",
      "Epoch 120/400\n",
      "323/323 [==============================] - 0s 93us/step - loss: 5.6847 - mean_absolute_error: 1.7497 - val_loss: 14.9902 - val_mean_absolute_error: 2.7223\n",
      "Epoch 121/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 5.6248 - mean_absolute_error: 1.7584 - val_loss: 14.8625 - val_mean_absolute_error: 2.7238\n",
      "Epoch 122/400\n",
      "323/323 [==============================] - 0s 90us/step - loss: 5.6917 - mean_absolute_error: 1.7660 - val_loss: 14.8323 - val_mean_absolute_error: 2.7292\n",
      "Epoch 123/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 5.6638 - mean_absolute_error: 1.7606 - val_loss: 14.5854 - val_mean_absolute_error: 2.7063\n",
      "Epoch 124/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 5.6044 - mean_absolute_error: 1.7515 - val_loss: 14.7230 - val_mean_absolute_error: 2.7039\n",
      "Epoch 125/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 6.1529 - mean_absolute_error: 1.8409 - val_loss: 14.5484 - val_mean_absolute_error: 2.7341\n",
      "Epoch 126/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 5.6301 - mean_absolute_error: 1.7646 - val_loss: 15.1384 - val_mean_absolute_error: 2.7628\n",
      "Epoch 127/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 5.9026 - mean_absolute_error: 1.8075 - val_loss: 14.6853 - val_mean_absolute_error: 2.7073\n",
      "Epoch 128/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 5.4495 - mean_absolute_error: 1.7300 - val_loss: 14.2565 - val_mean_absolute_error: 2.6411\n",
      "Epoch 129/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 5.6519 - mean_absolute_error: 1.7845 - val_loss: 14.2345 - val_mean_absolute_error: 2.6374\n",
      "Epoch 130/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 5.4018 - mean_absolute_error: 1.7193 - val_loss: 14.6449 - val_mean_absolute_error: 2.6811\n",
      "Epoch 131/400\n",
      "323/323 [==============================] - 0s 108us/step - loss: 5.5157 - mean_absolute_error: 1.7463 - val_loss: 14.7324 - val_mean_absolute_error: 2.6822\n",
      "Epoch 132/400\n",
      "323/323 [==============================] - 0s 95us/step - loss: 5.3195 - mean_absolute_error: 1.6998 - val_loss: 14.9868 - val_mean_absolute_error: 2.6849\n",
      "Epoch 133/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 5.4296 - mean_absolute_error: 1.6978 - val_loss: 15.2705 - val_mean_absolute_error: 2.7174\n",
      "Epoch 134/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 5.5727 - mean_absolute_error: 1.7381 - val_loss: 14.9431 - val_mean_absolute_error: 2.7053\n",
      "Epoch 135/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 5.4093 - mean_absolute_error: 1.7241 - val_loss: 15.1806 - val_mean_absolute_error: 2.7352\n",
      "Epoch 136/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 5.2624 - mean_absolute_error: 1.6976 - val_loss: 14.7544 - val_mean_absolute_error: 2.6925\n",
      "Epoch 137/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 5.1910 - mean_absolute_error: 1.6898 - val_loss: 14.7074 - val_mean_absolute_error: 2.6825\n",
      "Epoch 138/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 5.1016 - mean_absolute_error: 1.6749 - val_loss: 14.5976 - val_mean_absolute_error: 2.6699\n",
      "Epoch 139/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 5.0865 - mean_absolute_error: 1.6712 - val_loss: 14.4608 - val_mean_absolute_error: 2.6569\n",
      "Epoch 140/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 5.1066 - mean_absolute_error: 1.6856 - val_loss: 14.4455 - val_mean_absolute_error: 2.6603\n",
      "Epoch 141/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 5.0201 - mean_absolute_error: 1.6731 - val_loss: 14.5580 - val_mean_absolute_error: 2.6574\n",
      "Epoch 142/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 5.0280 - mean_absolute_error: 1.6483 - val_loss: 14.5959 - val_mean_absolute_error: 2.6560\n",
      "Epoch 143/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 4.9635 - mean_absolute_error: 1.6499 - val_loss: 14.4377 - val_mean_absolute_error: 2.6573\n",
      "Epoch 144/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 5.1500 - mean_absolute_error: 1.7144 - val_loss: 14.2458 - val_mean_absolute_error: 2.6699\n",
      "Epoch 145/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 5.0059 - mean_absolute_error: 1.6715 - val_loss: 14.1434 - val_mean_absolute_error: 2.6409\n",
      "Epoch 146/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 79us/step - loss: 5.1118 - mean_absolute_error: 1.6631 - val_loss: 13.9962 - val_mean_absolute_error: 2.6017\n",
      "Epoch 147/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 4.9471 - mean_absolute_error: 1.6404 - val_loss: 14.1067 - val_mean_absolute_error: 2.6137\n",
      "Epoch 148/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 4.8707 - mean_absolute_error: 1.6497 - val_loss: 14.1535 - val_mean_absolute_error: 2.6080\n",
      "Epoch 149/400\n",
      "323/323 [==============================] - 0s 86us/step - loss: 4.8594 - mean_absolute_error: 1.6257 - val_loss: 14.3765 - val_mean_absolute_error: 2.6370\n",
      "Epoch 150/400\n",
      "323/323 [==============================] - 0s 105us/step - loss: 4.9189 - mean_absolute_error: 1.6408 - val_loss: 14.4798 - val_mean_absolute_error: 2.6484\n",
      "Epoch 151/400\n",
      "323/323 [==============================] - 0s 107us/step - loss: 4.9614 - mean_absolute_error: 1.6692 - val_loss: 14.1486 - val_mean_absolute_error: 2.5932\n",
      "Epoch 152/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 4.7901 - mean_absolute_error: 1.6014 - val_loss: 14.3732 - val_mean_absolute_error: 2.6244\n",
      "Epoch 153/400\n",
      "323/323 [==============================] - 0s 91us/step - loss: 4.7384 - mean_absolute_error: 1.5980 - val_loss: 13.9868 - val_mean_absolute_error: 2.5444\n",
      "Epoch 154/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 4.8278 - mean_absolute_error: 1.6265 - val_loss: 13.9712 - val_mean_absolute_error: 2.5579\n",
      "Epoch 155/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 4.6883 - mean_absolute_error: 1.6089 - val_loss: 14.0690 - val_mean_absolute_error: 2.5876\n",
      "Epoch 156/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 4.7323 - mean_absolute_error: 1.6018 - val_loss: 14.0938 - val_mean_absolute_error: 2.5914\n",
      "Epoch 157/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.7579 - mean_absolute_error: 1.6413 - val_loss: 13.9467 - val_mean_absolute_error: 2.5716\n",
      "Epoch 158/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 4.6416 - mean_absolute_error: 1.6031 - val_loss: 13.9435 - val_mean_absolute_error: 2.5549\n",
      "Epoch 159/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 4.6283 - mean_absolute_error: 1.5859 - val_loss: 14.0819 - val_mean_absolute_error: 2.5713\n",
      "Epoch 160/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 4.5484 - mean_absolute_error: 1.5746 - val_loss: 14.0596 - val_mean_absolute_error: 2.5755\n",
      "Epoch 161/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 4.5463 - mean_absolute_error: 1.5779 - val_loss: 14.1531 - val_mean_absolute_error: 2.5716\n",
      "Epoch 162/400\n",
      "323/323 [==============================] - 0s 86us/step - loss: 4.4815 - mean_absolute_error: 1.5661 - val_loss: 13.9059 - val_mean_absolute_error: 2.5478\n",
      "Epoch 163/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 4.5879 - mean_absolute_error: 1.5968 - val_loss: 13.7892 - val_mean_absolute_error: 2.5459\n",
      "Epoch 164/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 4.4940 - mean_absolute_error: 1.5844 - val_loss: 13.6971 - val_mean_absolute_error: 2.5256\n",
      "Epoch 165/400\n",
      "323/323 [==============================] - 0s 96us/step - loss: 4.6165 - mean_absolute_error: 1.6097 - val_loss: 14.3116 - val_mean_absolute_error: 2.6148\n",
      "Epoch 166/400\n",
      "323/323 [==============================] - 0s 97us/step - loss: 4.5011 - mean_absolute_error: 1.5668 - val_loss: 14.1190 - val_mean_absolute_error: 2.6016\n",
      "Epoch 167/400\n",
      "323/323 [==============================] - 0s 101us/step - loss: 4.4454 - mean_absolute_error: 1.5659 - val_loss: 13.7375 - val_mean_absolute_error: 2.5597\n",
      "Epoch 168/400\n",
      "323/323 [==============================] - 0s 93us/step - loss: 4.4047 - mean_absolute_error: 1.5629 - val_loss: 13.7794 - val_mean_absolute_error: 2.5659\n",
      "Epoch 169/400\n",
      "323/323 [==============================] - 0s 109us/step - loss: 4.4140 - mean_absolute_error: 1.5514 - val_loss: 13.9979 - val_mean_absolute_error: 2.5655\n",
      "Epoch 170/400\n",
      "323/323 [==============================] - 0s 96us/step - loss: 4.3431 - mean_absolute_error: 1.5263 - val_loss: 14.1016 - val_mean_absolute_error: 2.5788\n",
      "Epoch 171/400\n",
      "323/323 [==============================] - 0s 95us/step - loss: 4.3618 - mean_absolute_error: 1.5436 - val_loss: 13.7982 - val_mean_absolute_error: 2.5653\n",
      "Epoch 172/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 4.6550 - mean_absolute_error: 1.6414 - val_loss: 14.5772 - val_mean_absolute_error: 2.6584\n",
      "Epoch 173/400\n",
      "323/323 [==============================] - 0s 86us/step - loss: 4.3644 - mean_absolute_error: 1.5727 - val_loss: 14.6983 - val_mean_absolute_error: 2.6625\n",
      "Epoch 174/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 4.3211 - mean_absolute_error: 1.5424 - val_loss: 14.4803 - val_mean_absolute_error: 2.6379\n",
      "Epoch 175/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 4.3016 - mean_absolute_error: 1.5447 - val_loss: 14.0908 - val_mean_absolute_error: 2.5764\n",
      "Epoch 176/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 4.2567 - mean_absolute_error: 1.5350 - val_loss: 13.7156 - val_mean_absolute_error: 2.5387\n",
      "Epoch 177/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 4.2016 - mean_absolute_error: 1.5126 - val_loss: 13.8003 - val_mean_absolute_error: 2.5420\n",
      "Epoch 178/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 4.2359 - mean_absolute_error: 1.5113 - val_loss: 13.7667 - val_mean_absolute_error: 2.5645\n",
      "Epoch 179/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 4.2402 - mean_absolute_error: 1.5418 - val_loss: 13.8128 - val_mean_absolute_error: 2.5855\n",
      "Epoch 180/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 4.1367 - mean_absolute_error: 1.5087 - val_loss: 13.7257 - val_mean_absolute_error: 2.5166\n",
      "Epoch 181/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 4.2110 - mean_absolute_error: 1.5341 - val_loss: 14.5497 - val_mean_absolute_error: 2.6487\n",
      "Epoch 182/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 4.3575 - mean_absolute_error: 1.5459 - val_loss: 14.2400 - val_mean_absolute_error: 2.5634\n",
      "Epoch 183/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 4.1278 - mean_absolute_error: 1.4986 - val_loss: 13.6319 - val_mean_absolute_error: 2.5062\n",
      "Epoch 184/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 4.0971 - mean_absolute_error: 1.5126 - val_loss: 13.6358 - val_mean_absolute_error: 2.5045\n",
      "Epoch 185/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.0627 - mean_absolute_error: 1.4837 - val_loss: 13.5536 - val_mean_absolute_error: 2.4889\n",
      "Epoch 186/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.2804 - mean_absolute_error: 1.5310 - val_loss: 13.4918 - val_mean_absolute_error: 2.5147\n",
      "Epoch 187/400\n",
      "323/323 [==============================] - 0s 100us/step - loss: 3.9862 - mean_absolute_error: 1.4908 - val_loss: 13.5633 - val_mean_absolute_error: 2.5512\n",
      "Epoch 188/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 4.1941 - mean_absolute_error: 1.5348 - val_loss: 13.4718 - val_mean_absolute_error: 2.5069\n",
      "Epoch 189/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 3.9723 - mean_absolute_error: 1.4694 - val_loss: 13.5757 - val_mean_absolute_error: 2.4939\n",
      "Epoch 190/400\n",
      "323/323 [==============================] - 0s 93us/step - loss: 4.1165 - mean_absolute_error: 1.4783 - val_loss: 13.8415 - val_mean_absolute_error: 2.4929\n",
      "Epoch 191/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 4.0415 - mean_absolute_error: 1.4927 - val_loss: 13.9689 - val_mean_absolute_error: 2.5261\n",
      "Epoch 192/400\n",
      "323/323 [==============================] - 0s 97us/step - loss: 4.0594 - mean_absolute_error: 1.5058 - val_loss: 13.4291 - val_mean_absolute_error: 2.4681\n",
      "Epoch 193/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 4.4854 - mean_absolute_error: 1.5214 - val_loss: 14.0642 - val_mean_absolute_error: 2.5532\n",
      "Epoch 194/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 79us/step - loss: 4.1329 - mean_absolute_error: 1.5019 - val_loss: 13.9292 - val_mean_absolute_error: 2.5542\n",
      "Epoch 195/400\n",
      "323/323 [==============================] - 0s 89us/step - loss: 4.0726 - mean_absolute_error: 1.5171 - val_loss: 13.5024 - val_mean_absolute_error: 2.4990\n",
      "Epoch 196/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.9118 - mean_absolute_error: 1.4865 - val_loss: 13.1404 - val_mean_absolute_error: 2.5101\n",
      "Epoch 197/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 3.8754 - mean_absolute_error: 1.4654 - val_loss: 13.1046 - val_mean_absolute_error: 2.4851\n",
      "Epoch 198/400\n",
      "323/323 [==============================] - 0s 104us/step - loss: 3.8943 - mean_absolute_error: 1.4598 - val_loss: 13.4791 - val_mean_absolute_error: 2.5416\n",
      "Epoch 199/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.7826 - mean_absolute_error: 1.4463 - val_loss: 13.5453 - val_mean_absolute_error: 2.5304\n",
      "Epoch 200/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 4.0083 - mean_absolute_error: 1.4682 - val_loss: 14.1472 - val_mean_absolute_error: 2.5564\n",
      "Epoch 201/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 3.8331 - mean_absolute_error: 1.4335 - val_loss: 13.7948 - val_mean_absolute_error: 2.5579\n",
      "Epoch 202/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 3.7332 - mean_absolute_error: 1.4320 - val_loss: 13.5961 - val_mean_absolute_error: 2.4895\n",
      "Epoch 203/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 3.7297 - mean_absolute_error: 1.4349 - val_loss: 13.6663 - val_mean_absolute_error: 2.5119\n",
      "Epoch 204/400\n",
      "323/323 [==============================] - 0s 89us/step - loss: 3.7368 - mean_absolute_error: 1.4422 - val_loss: 13.3839 - val_mean_absolute_error: 2.4782\n",
      "Epoch 205/400\n",
      "323/323 [==============================] - 0s 68us/step - loss: 3.7395 - mean_absolute_error: 1.4316 - val_loss: 13.5827 - val_mean_absolute_error: 2.5230\n",
      "Epoch 206/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 4.0296 - mean_absolute_error: 1.4902 - val_loss: 13.6953 - val_mean_absolute_error: 2.5691\n",
      "Epoch 207/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 3.6891 - mean_absolute_error: 1.4419 - val_loss: 13.5347 - val_mean_absolute_error: 2.5421\n",
      "Epoch 208/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 4.1055 - mean_absolute_error: 1.4819 - val_loss: 13.7094 - val_mean_absolute_error: 2.4978\n",
      "Epoch 209/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.7339 - mean_absolute_error: 1.4248 - val_loss: 13.6586 - val_mean_absolute_error: 2.5470\n",
      "Epoch 210/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 3.6047 - mean_absolute_error: 1.4162 - val_loss: 13.5825 - val_mean_absolute_error: 2.5098\n",
      "Epoch 211/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 3.6670 - mean_absolute_error: 1.4194 - val_loss: 13.2573 - val_mean_absolute_error: 2.4986\n",
      "Epoch 212/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 3.5802 - mean_absolute_error: 1.4027 - val_loss: 13.0721 - val_mean_absolute_error: 2.4712\n",
      "Epoch 213/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 3.5693 - mean_absolute_error: 1.4071 - val_loss: 13.6415 - val_mean_absolute_error: 2.5781\n",
      "Epoch 214/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 3.6790 - mean_absolute_error: 1.4361 - val_loss: 14.0527 - val_mean_absolute_error: 2.6179\n",
      "Epoch 215/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.7146 - mean_absolute_error: 1.4512 - val_loss: 14.3370 - val_mean_absolute_error: 2.6423\n",
      "Epoch 216/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 3.5617 - mean_absolute_error: 1.4147 - val_loss: 13.4658 - val_mean_absolute_error: 2.5114\n",
      "Epoch 217/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 3.5225 - mean_absolute_error: 1.3972 - val_loss: 12.9484 - val_mean_absolute_error: 2.4392\n",
      "Epoch 218/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 3.4892 - mean_absolute_error: 1.4094 - val_loss: 13.2520 - val_mean_absolute_error: 2.4824\n",
      "Epoch 219/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 3.4638 - mean_absolute_error: 1.3866 - val_loss: 13.2518 - val_mean_absolute_error: 2.4682\n",
      "Epoch 220/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 3.6531 - mean_absolute_error: 1.4161 - val_loss: 12.5399 - val_mean_absolute_error: 2.3834\n",
      "Epoch 221/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.5768 - mean_absolute_error: 1.4290 - val_loss: 12.3839 - val_mean_absolute_error: 2.4071\n",
      "Epoch 222/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 3.4120 - mean_absolute_error: 1.3708 - val_loss: 12.8042 - val_mean_absolute_error: 2.4625\n",
      "Epoch 223/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.3627 - mean_absolute_error: 1.3562 - val_loss: 12.9349 - val_mean_absolute_error: 2.4799\n",
      "Epoch 224/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.3557 - mean_absolute_error: 1.3735 - val_loss: 13.5324 - val_mean_absolute_error: 2.5117\n",
      "Epoch 225/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 3.4272 - mean_absolute_error: 1.3709 - val_loss: 13.4643 - val_mean_absolute_error: 2.4797\n",
      "Epoch 226/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 3.4112 - mean_absolute_error: 1.3804 - val_loss: 12.7744 - val_mean_absolute_error: 2.4209\n",
      "Epoch 227/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 3.3201 - mean_absolute_error: 1.3550 - val_loss: 13.0142 - val_mean_absolute_error: 2.4888\n",
      "Epoch 228/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 3.2690 - mean_absolute_error: 1.3517 - val_loss: 12.9889 - val_mean_absolute_error: 2.4758\n",
      "Epoch 229/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.2619 - mean_absolute_error: 1.3454 - val_loss: 13.3368 - val_mean_absolute_error: 2.5135\n",
      "Epoch 230/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 3.3048 - mean_absolute_error: 1.3447 - val_loss: 13.4638 - val_mean_absolute_error: 2.5164\n",
      "Epoch 231/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 3.2870 - mean_absolute_error: 1.3477 - val_loss: 13.1518 - val_mean_absolute_error: 2.4722\n",
      "Epoch 232/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 3.2753 - mean_absolute_error: 1.3414 - val_loss: 13.0995 - val_mean_absolute_error: 2.4507\n",
      "Epoch 233/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 3.2167 - mean_absolute_error: 1.3289 - val_loss: 12.8529 - val_mean_absolute_error: 2.4339\n",
      "Epoch 234/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 3.1772 - mean_absolute_error: 1.3411 - val_loss: 12.8512 - val_mean_absolute_error: 2.4613\n",
      "Epoch 235/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 3.4150 - mean_absolute_error: 1.3898 - val_loss: 12.3325 - val_mean_absolute_error: 2.4190\n",
      "Epoch 236/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 3.2756 - mean_absolute_error: 1.3600 - val_loss: 13.3895 - val_mean_absolute_error: 2.5576\n",
      "Epoch 237/400\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.2760 - mean_absolute_error: 1.3615 - val_loss: 13.0630 - val_mean_absolute_error: 2.4771\n",
      "Epoch 238/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 3.1436 - mean_absolute_error: 1.3238 - val_loss: 12.9097 - val_mean_absolute_error: 2.4519\n",
      "Epoch 239/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 3.2860 - mean_absolute_error: 1.3723 - val_loss: 12.5097 - val_mean_absolute_error: 2.4167\n",
      "Epoch 240/400\n",
      "323/323 [==============================] - 0s 92us/step - loss: 3.2766 - mean_absolute_error: 1.3364 - val_loss: 13.2235 - val_mean_absolute_error: 2.4844\n",
      "Epoch 241/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 3.1756 - mean_absolute_error: 1.3384 - val_loss: 13.2373 - val_mean_absolute_error: 2.4878\n",
      "Epoch 242/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 88us/step - loss: 3.2990 - mean_absolute_error: 1.3421 - val_loss: 13.2747 - val_mean_absolute_error: 2.4719\n",
      "Epoch 243/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 3.0363 - mean_absolute_error: 1.3015 - val_loss: 13.1216 - val_mean_absolute_error: 2.4903\n",
      "Epoch 244/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 3.1081 - mean_absolute_error: 1.3299 - val_loss: 12.8462 - val_mean_absolute_error: 2.4372\n",
      "Epoch 245/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.0949 - mean_absolute_error: 1.2988 - val_loss: 12.8805 - val_mean_absolute_error: 2.4313\n",
      "Epoch 246/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 3.0636 - mean_absolute_error: 1.3118 - val_loss: 13.1662 - val_mean_absolute_error: 2.4853\n",
      "Epoch 247/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 3.0469 - mean_absolute_error: 1.2970 - val_loss: 13.5599 - val_mean_absolute_error: 2.4982\n",
      "Epoch 248/400\n",
      "323/323 [==============================] - 0s 95us/step - loss: 3.1493 - mean_absolute_error: 1.3114 - val_loss: 13.0109 - val_mean_absolute_error: 2.4511\n",
      "Epoch 249/400\n",
      "323/323 [==============================] - 0s 93us/step - loss: 3.2779 - mean_absolute_error: 1.3645 - val_loss: 12.5679 - val_mean_absolute_error: 2.3872\n",
      "Epoch 250/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 3.0116 - mean_absolute_error: 1.2909 - val_loss: 13.3062 - val_mean_absolute_error: 2.4906\n",
      "Epoch 251/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 3.0996 - mean_absolute_error: 1.3415 - val_loss: 13.4039 - val_mean_absolute_error: 2.4841\n",
      "Epoch 252/400\n",
      "323/323 [==============================] - 0s 108us/step - loss: 3.2887 - mean_absolute_error: 1.3385 - val_loss: 13.3339 - val_mean_absolute_error: 2.4937\n",
      "Epoch 253/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 2.9447 - mean_absolute_error: 1.2879 - val_loss: 12.9186 - val_mean_absolute_error: 2.4523\n",
      "Epoch 254/400\n",
      "323/323 [==============================] - 0s 104us/step - loss: 2.9348 - mean_absolute_error: 1.2740 - val_loss: 13.1644 - val_mean_absolute_error: 2.4803\n",
      "Epoch 255/400\n",
      "323/323 [==============================] - 0s 103us/step - loss: 2.9929 - mean_absolute_error: 1.2765 - val_loss: 12.7616 - val_mean_absolute_error: 2.3943\n",
      "Epoch 256/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 3.2672 - mean_absolute_error: 1.3825 - val_loss: 11.9374 - val_mean_absolute_error: 2.3187\n",
      "Epoch 257/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 2.9600 - mean_absolute_error: 1.2911 - val_loss: 12.4564 - val_mean_absolute_error: 2.3939\n",
      "Epoch 258/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 2.9432 - mean_absolute_error: 1.2696 - val_loss: 12.6238 - val_mean_absolute_error: 2.4074\n",
      "Epoch 259/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 3.0861 - mean_absolute_error: 1.3380 - val_loss: 13.2127 - val_mean_absolute_error: 2.4811\n",
      "Epoch 260/400\n",
      "323/323 [==============================] - 0s 91us/step - loss: 3.2804 - mean_absolute_error: 1.3537 - val_loss: 12.9072 - val_mean_absolute_error: 2.4198\n",
      "Epoch 261/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 2.8610 - mean_absolute_error: 1.2530 - val_loss: 12.3177 - val_mean_absolute_error: 2.3407\n",
      "Epoch 262/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 2.8828 - mean_absolute_error: 1.2624 - val_loss: 12.3553 - val_mean_absolute_error: 2.3698\n",
      "Epoch 263/400\n",
      "323/323 [==============================] - 0s 106us/step - loss: 2.8038 - mean_absolute_error: 1.2521 - val_loss: 12.8029 - val_mean_absolute_error: 2.4504\n",
      "Epoch 264/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 3.0061 - mean_absolute_error: 1.2757 - val_loss: 12.8835 - val_mean_absolute_error: 2.4538\n",
      "Epoch 265/400\n",
      "323/323 [==============================] - 0s 97us/step - loss: 2.9346 - mean_absolute_error: 1.2686 - val_loss: 13.2112 - val_mean_absolute_error: 2.4700\n",
      "Epoch 266/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 2.9063 - mean_absolute_error: 1.2530 - val_loss: 12.5076 - val_mean_absolute_error: 2.4078\n",
      "Epoch 267/400\n",
      "323/323 [==============================] - 0s 96us/step - loss: 2.8119 - mean_absolute_error: 1.2524 - val_loss: 12.7832 - val_mean_absolute_error: 2.4566\n",
      "Epoch 268/400\n",
      "323/323 [==============================] - 0s 94us/step - loss: 2.9107 - mean_absolute_error: 1.2903 - val_loss: 12.9527 - val_mean_absolute_error: 2.4488\n",
      "Epoch 269/400\n",
      "323/323 [==============================] - 0s 107us/step - loss: 3.0394 - mean_absolute_error: 1.3067 - val_loss: 12.7930 - val_mean_absolute_error: 2.4371\n",
      "Epoch 270/400\n",
      "323/323 [==============================] - 0s 106us/step - loss: 2.7591 - mean_absolute_error: 1.2452 - val_loss: 12.6342 - val_mean_absolute_error: 2.4167\n",
      "Epoch 271/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.6912 - mean_absolute_error: 1.2213 - val_loss: 12.9905 - val_mean_absolute_error: 2.4586\n",
      "Epoch 272/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.7535 - mean_absolute_error: 1.2167 - val_loss: 12.9263 - val_mean_absolute_error: 2.4132\n",
      "Epoch 273/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.7255 - mean_absolute_error: 1.2339 - val_loss: 12.3153 - val_mean_absolute_error: 2.3405\n",
      "Epoch 274/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.7114 - mean_absolute_error: 1.2285 - val_loss: 12.4529 - val_mean_absolute_error: 2.3786\n",
      "Epoch 275/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 2.6398 - mean_absolute_error: 1.2039 - val_loss: 12.6674 - val_mean_absolute_error: 2.4168\n",
      "Epoch 276/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.6870 - mean_absolute_error: 1.2104 - val_loss: 12.5543 - val_mean_absolute_error: 2.4088\n",
      "Epoch 277/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.7065 - mean_absolute_error: 1.2275 - val_loss: 13.3590 - val_mean_absolute_error: 2.5587\n",
      "Epoch 278/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.6785 - mean_absolute_error: 1.2195 - val_loss: 13.0686 - val_mean_absolute_error: 2.4725\n",
      "Epoch 279/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.6308 - mean_absolute_error: 1.2029 - val_loss: 12.4003 - val_mean_absolute_error: 2.3583\n",
      "Epoch 280/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 2.5943 - mean_absolute_error: 1.1984 - val_loss: 12.4379 - val_mean_absolute_error: 2.3677\n",
      "Epoch 281/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.6023 - mean_absolute_error: 1.1822 - val_loss: 12.4940 - val_mean_absolute_error: 2.3682\n",
      "Epoch 282/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 2.5849 - mean_absolute_error: 1.1843 - val_loss: 12.4117 - val_mean_absolute_error: 2.3664\n",
      "Epoch 283/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 2.5627 - mean_absolute_error: 1.1819 - val_loss: 12.8311 - val_mean_absolute_error: 2.3978\n",
      "Epoch 284/400\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.6966 - mean_absolute_error: 1.1890 - val_loss: 13.3029 - val_mean_absolute_error: 2.4294\n",
      "Epoch 285/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 2.6003 - mean_absolute_error: 1.1954 - val_loss: 12.9518 - val_mean_absolute_error: 2.4313\n",
      "Epoch 286/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 2.6396 - mean_absolute_error: 1.2094 - val_loss: 12.6779 - val_mean_absolute_error: 2.3952\n",
      "Epoch 287/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.5535 - mean_absolute_error: 1.1756 - val_loss: 12.2926 - val_mean_absolute_error: 2.3429\n",
      "Epoch 288/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.5214 - mean_absolute_error: 1.1741 - val_loss: 12.6804 - val_mean_absolute_error: 2.4017\n",
      "Epoch 289/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.4972 - mean_absolute_error: 1.1507 - val_loss: 12.8456 - val_mean_absolute_error: 2.4353\n",
      "Epoch 290/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 71us/step - loss: 2.5165 - mean_absolute_error: 1.1723 - val_loss: 12.8929 - val_mean_absolute_error: 2.4389\n",
      "Epoch 291/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.5123 - mean_absolute_error: 1.1724 - val_loss: 12.7554 - val_mean_absolute_error: 2.4177\n",
      "Epoch 292/400\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.6025 - mean_absolute_error: 1.1987 - val_loss: 12.5692 - val_mean_absolute_error: 2.4399\n",
      "Epoch 293/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 2.8698 - mean_absolute_error: 1.2765 - val_loss: 13.8940 - val_mean_absolute_error: 2.5985\n",
      "Epoch 294/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 2.6501 - mean_absolute_error: 1.2106 - val_loss: 13.0943 - val_mean_absolute_error: 2.4648\n",
      "Epoch 295/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 2.6191 - mean_absolute_error: 1.2088 - val_loss: 12.3299 - val_mean_absolute_error: 2.3505\n",
      "Epoch 296/400\n",
      "323/323 [==============================] - 0s 85us/step - loss: 2.4915 - mean_absolute_error: 1.1578 - val_loss: 12.8444 - val_mean_absolute_error: 2.3916\n",
      "Epoch 297/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 2.6227 - mean_absolute_error: 1.1828 - val_loss: 12.8605 - val_mean_absolute_error: 2.4212\n",
      "Epoch 298/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.5456 - mean_absolute_error: 1.1867 - val_loss: 12.7660 - val_mean_absolute_error: 2.4095\n",
      "Epoch 299/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 2.4800 - mean_absolute_error: 1.1513 - val_loss: 12.8714 - val_mean_absolute_error: 2.3997\n",
      "Epoch 300/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 2.4786 - mean_absolute_error: 1.1622 - val_loss: 12.5561 - val_mean_absolute_error: 2.3749\n",
      "Epoch 301/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 2.4159 - mean_absolute_error: 1.1390 - val_loss: 12.5897 - val_mean_absolute_error: 2.3872\n",
      "Epoch 302/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.4021 - mean_absolute_error: 1.1413 - val_loss: 13.0114 - val_mean_absolute_error: 2.4303\n",
      "Epoch 303/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.4637 - mean_absolute_error: 1.1521 - val_loss: 12.3858 - val_mean_absolute_error: 2.3415\n",
      "Epoch 304/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 2.3871 - mean_absolute_error: 1.1359 - val_loss: 12.5901 - val_mean_absolute_error: 2.3980\n",
      "Epoch 305/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.3320 - mean_absolute_error: 1.1108 - val_loss: 12.5899 - val_mean_absolute_error: 2.3830\n",
      "Epoch 306/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 2.4140 - mean_absolute_error: 1.1578 - val_loss: 12.4883 - val_mean_absolute_error: 2.3712\n",
      "Epoch 307/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 2.3602 - mean_absolute_error: 1.1158 - val_loss: 12.4766 - val_mean_absolute_error: 2.3528\n",
      "Epoch 308/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.4408 - mean_absolute_error: 1.1691 - val_loss: 13.1857 - val_mean_absolute_error: 2.4584\n",
      "Epoch 309/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.3903 - mean_absolute_error: 1.1362 - val_loss: 12.8964 - val_mean_absolute_error: 2.4214\n",
      "Epoch 310/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.3406 - mean_absolute_error: 1.1208 - val_loss: 12.7110 - val_mean_absolute_error: 2.4075\n",
      "Epoch 311/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.4282 - mean_absolute_error: 1.1505 - val_loss: 12.7512 - val_mean_absolute_error: 2.4185\n",
      "Epoch 312/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 2.3782 - mean_absolute_error: 1.1257 - val_loss: 12.9591 - val_mean_absolute_error: 2.4288\n",
      "Epoch 313/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.3354 - mean_absolute_error: 1.1076 - val_loss: 12.7614 - val_mean_absolute_error: 2.3950\n",
      "Epoch 314/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.4265 - mean_absolute_error: 1.1558 - val_loss: 12.9281 - val_mean_absolute_error: 2.4271\n",
      "Epoch 315/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.3226 - mean_absolute_error: 1.1218 - val_loss: 12.7129 - val_mean_absolute_error: 2.4061\n",
      "Epoch 316/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 2.4680 - mean_absolute_error: 1.1555 - val_loss: 13.1814 - val_mean_absolute_error: 2.4491\n",
      "Epoch 317/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.4303 - mean_absolute_error: 1.1307 - val_loss: 12.6325 - val_mean_absolute_error: 2.4046\n",
      "Epoch 318/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 2.3447 - mean_absolute_error: 1.1404 - val_loss: 12.2916 - val_mean_absolute_error: 2.3543\n",
      "Epoch 319/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 2.4591 - mean_absolute_error: 1.1458 - val_loss: 12.8245 - val_mean_absolute_error: 2.4144\n",
      "Epoch 320/400\n",
      "323/323 [==============================] - 0s 82us/step - loss: 2.5365 - mean_absolute_error: 1.1768 - val_loss: 12.5057 - val_mean_absolute_error: 2.3753\n",
      "Epoch 321/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.5178 - mean_absolute_error: 1.1651 - val_loss: 12.9526 - val_mean_absolute_error: 2.4465\n",
      "Epoch 322/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 2.9688 - mean_absolute_error: 1.3136 - val_loss: 11.9698 - val_mean_absolute_error: 2.2968\n",
      "Epoch 323/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.6217 - mean_absolute_error: 1.2080 - val_loss: 12.3013 - val_mean_absolute_error: 2.3341\n",
      "Epoch 324/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 2.4378 - mean_absolute_error: 1.1575 - val_loss: 12.7936 - val_mean_absolute_error: 2.4098\n",
      "Epoch 325/400\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.2527 - mean_absolute_error: 1.1192 - val_loss: 12.5767 - val_mean_absolute_error: 2.3896\n",
      "Epoch 326/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.2142 - mean_absolute_error: 1.0766 - val_loss: 12.5759 - val_mean_absolute_error: 2.3826\n",
      "Epoch 327/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.2590 - mean_absolute_error: 1.1029 - val_loss: 12.1942 - val_mean_absolute_error: 2.3500\n",
      "Epoch 328/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 2.2342 - mean_absolute_error: 1.0942 - val_loss: 12.5024 - val_mean_absolute_error: 2.3769\n",
      "Epoch 329/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 2.2935 - mean_absolute_error: 1.1098 - val_loss: 12.2709 - val_mean_absolute_error: 2.3486\n",
      "Epoch 330/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.1801 - mean_absolute_error: 1.0725 - val_loss: 12.6910 - val_mean_absolute_error: 2.3909\n",
      "Epoch 331/400\n",
      "323/323 [==============================] - 0s 66us/step - loss: 2.1645 - mean_absolute_error: 1.0726 - val_loss: 12.5684 - val_mean_absolute_error: 2.3683\n",
      "Epoch 332/400\n",
      "323/323 [==============================] - 0s 87us/step - loss: 2.1724 - mean_absolute_error: 1.0706 - val_loss: 12.3626 - val_mean_absolute_error: 2.3558\n",
      "Epoch 333/400\n",
      "323/323 [==============================] - 0s 66us/step - loss: 2.1321 - mean_absolute_error: 1.0514 - val_loss: 12.3536 - val_mean_absolute_error: 2.3365\n",
      "Epoch 334/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.1466 - mean_absolute_error: 1.0645 - val_loss: 12.8384 - val_mean_absolute_error: 2.4268\n",
      "Epoch 335/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.2209 - mean_absolute_error: 1.0766 - val_loss: 12.6120 - val_mean_absolute_error: 2.4315\n",
      "Epoch 336/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 2.1670 - mean_absolute_error: 1.0638 - val_loss: 12.0529 - val_mean_absolute_error: 2.2912\n",
      "Epoch 337/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 2.1345 - mean_absolute_error: 1.0649 - val_loss: 12.3620 - val_mean_absolute_error: 2.3376\n",
      "Epoch 338/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 75us/step - loss: 2.1421 - mean_absolute_error: 1.0613 - val_loss: 12.6586 - val_mean_absolute_error: 2.4304\n",
      "Epoch 339/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.1070 - mean_absolute_error: 1.0557 - val_loss: 12.4251 - val_mean_absolute_error: 2.3761\n",
      "Epoch 340/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.1536 - mean_absolute_error: 1.0722 - val_loss: 12.1886 - val_mean_absolute_error: 2.3183\n",
      "Epoch 341/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.1226 - mean_absolute_error: 1.0436 - val_loss: 12.4589 - val_mean_absolute_error: 2.3780\n",
      "Epoch 342/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 2.1814 - mean_absolute_error: 1.0774 - val_loss: 12.3400 - val_mean_absolute_error: 2.3296\n",
      "Epoch 343/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 2.2064 - mean_absolute_error: 1.0809 - val_loss: 12.2191 - val_mean_absolute_error: 2.3486\n",
      "Epoch 344/400\n",
      "323/323 [==============================] - 0s 84us/step - loss: 2.1784 - mean_absolute_error: 1.0845 - val_loss: 12.7436 - val_mean_absolute_error: 2.3607\n",
      "Epoch 345/400\n",
      "323/323 [==============================] - 0s 72us/step - loss: 2.1796 - mean_absolute_error: 1.0798 - val_loss: 12.8843 - val_mean_absolute_error: 2.3684\n",
      "Epoch 346/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.0621 - mean_absolute_error: 1.0473 - val_loss: 12.5788 - val_mean_absolute_error: 2.3681\n",
      "Epoch 347/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.0417 - mean_absolute_error: 1.0293 - val_loss: 12.4039 - val_mean_absolute_error: 2.3538\n",
      "Epoch 348/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.0560 - mean_absolute_error: 1.0511 - val_loss: 12.5499 - val_mean_absolute_error: 2.3709\n",
      "Epoch 349/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 2.0373 - mean_absolute_error: 1.0235 - val_loss: 12.4979 - val_mean_absolute_error: 2.3551\n",
      "Epoch 350/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 2.2074 - mean_absolute_error: 1.1065 - val_loss: 12.8087 - val_mean_absolute_error: 2.3987\n",
      "Epoch 351/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 2.1172 - mean_absolute_error: 1.0606 - val_loss: 12.9532 - val_mean_absolute_error: 2.4123\n",
      "Epoch 352/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.0338 - mean_absolute_error: 1.0433 - val_loss: 12.8301 - val_mean_absolute_error: 2.3950\n",
      "Epoch 353/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 2.2407 - mean_absolute_error: 1.0845 - val_loss: 13.1856 - val_mean_absolute_error: 2.5088\n",
      "Epoch 354/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.2585 - mean_absolute_error: 1.1098 - val_loss: 12.5024 - val_mean_absolute_error: 2.3801\n",
      "Epoch 355/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.1312 - mean_absolute_error: 1.0649 - val_loss: 12.6856 - val_mean_absolute_error: 2.3775\n",
      "Epoch 356/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.0493 - mean_absolute_error: 1.0440 - val_loss: 12.6538 - val_mean_absolute_error: 2.3580\n",
      "Epoch 357/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.0080 - mean_absolute_error: 1.0164 - val_loss: 13.2140 - val_mean_absolute_error: 2.4440\n",
      "Epoch 358/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 2.0040 - mean_absolute_error: 1.0353 - val_loss: 12.9099 - val_mean_absolute_error: 2.4094\n",
      "Epoch 359/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 2.0892 - mean_absolute_error: 1.0414 - val_loss: 12.6163 - val_mean_absolute_error: 2.3737\n",
      "Epoch 360/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.0279 - mean_absolute_error: 1.0392 - val_loss: 12.5892 - val_mean_absolute_error: 2.3670\n",
      "Epoch 361/400\n",
      "323/323 [==============================] - 0s 73us/step - loss: 1.9631 - mean_absolute_error: 0.9991 - val_loss: 12.8541 - val_mean_absolute_error: 2.3957\n",
      "Epoch 362/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 1.9770 - mean_absolute_error: 1.0328 - val_loss: 12.8355 - val_mean_absolute_error: 2.4042\n",
      "Epoch 363/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 1.9479 - mean_absolute_error: 0.9989 - val_loss: 12.6399 - val_mean_absolute_error: 2.3584\n",
      "Epoch 364/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.2087 - mean_absolute_error: 1.1054 - val_loss: 12.9584 - val_mean_absolute_error: 2.4255\n",
      "Epoch 365/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 2.0418 - mean_absolute_error: 1.0359 - val_loss: 12.9983 - val_mean_absolute_error: 2.4409\n",
      "Epoch 366/400\n",
      "323/323 [==============================] - 0s 68us/step - loss: 1.9650 - mean_absolute_error: 1.0110 - val_loss: 12.6454 - val_mean_absolute_error: 2.3756\n",
      "Epoch 367/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.2079 - mean_absolute_error: 1.0911 - val_loss: 12.2902 - val_mean_absolute_error: 2.3748\n",
      "Epoch 368/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 2.0086 - mean_absolute_error: 1.0051 - val_loss: 12.3305 - val_mean_absolute_error: 2.3449\n",
      "Epoch 369/400\n",
      "323/323 [==============================] - 0s 86us/step - loss: 2.1216 - mean_absolute_error: 1.0687 - val_loss: 12.0974 - val_mean_absolute_error: 2.3242\n",
      "Epoch 370/400\n",
      "323/323 [==============================] - 0s 75us/step - loss: 2.0353 - mean_absolute_error: 1.0329 - val_loss: 12.5650 - val_mean_absolute_error: 2.3635\n",
      "Epoch 371/400\n",
      "323/323 [==============================] - 0s 79us/step - loss: 1.9344 - mean_absolute_error: 1.0171 - val_loss: 13.1138 - val_mean_absolute_error: 2.4156\n",
      "Epoch 372/400\n",
      "323/323 [==============================] - 0s 93us/step - loss: 1.9148 - mean_absolute_error: 0.9951 - val_loss: 12.7885 - val_mean_absolute_error: 2.3690\n",
      "Epoch 373/400\n",
      "323/323 [==============================] - 0s 65us/step - loss: 2.1259 - mean_absolute_error: 1.0827 - val_loss: 12.5510 - val_mean_absolute_error: 2.3428\n",
      "Epoch 374/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 2.0354 - mean_absolute_error: 1.0512 - val_loss: 12.3499 - val_mean_absolute_error: 2.3546\n",
      "Epoch 375/400\n",
      "323/323 [==============================] - 0s 65us/step - loss: 1.9081 - mean_absolute_error: 0.9902 - val_loss: 12.2771 - val_mean_absolute_error: 2.2994\n",
      "Epoch 376/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 1.9258 - mean_absolute_error: 1.0041 - val_loss: 12.6749 - val_mean_absolute_error: 2.3721\n",
      "Epoch 377/400\n",
      "323/323 [==============================] - 0s 67us/step - loss: 1.9439 - mean_absolute_error: 0.9795 - val_loss: 12.5123 - val_mean_absolute_error: 2.3344\n",
      "Epoch 378/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 1.8706 - mean_absolute_error: 0.9877 - val_loss: 12.4128 - val_mean_absolute_error: 2.3299\n",
      "Epoch 379/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 1.8560 - mean_absolute_error: 0.9651 - val_loss: 12.5922 - val_mean_absolute_error: 2.3269\n",
      "Epoch 380/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 1.8542 - mean_absolute_error: 0.9804 - val_loss: 12.1883 - val_mean_absolute_error: 2.3406\n",
      "Epoch 381/400\n",
      "323/323 [==============================] - 0s 66us/step - loss: 1.9189 - mean_absolute_error: 0.9986 - val_loss: 12.4241 - val_mean_absolute_error: 2.3627\n",
      "Epoch 382/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 1.9619 - mean_absolute_error: 1.0079 - val_loss: 12.6300 - val_mean_absolute_error: 2.3061\n",
      "Epoch 383/400\n",
      "323/323 [==============================] - 0s 63us/step - loss: 1.9135 - mean_absolute_error: 0.9894 - val_loss: 12.0840 - val_mean_absolute_error: 2.2980\n",
      "Epoch 384/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 1.8857 - mean_absolute_error: 0.9935 - val_loss: 12.0652 - val_mean_absolute_error: 2.3269\n",
      "Epoch 385/400\n",
      "323/323 [==============================] - 0s 71us/step - loss: 1.8897 - mean_absolute_error: 0.9829 - val_loss: 12.4455 - val_mean_absolute_error: 2.3486\n",
      "Epoch 386/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/323 [==============================] - 0s 71us/step - loss: 1.9173 - mean_absolute_error: 1.0031 - val_loss: 12.3666 - val_mean_absolute_error: 2.3249\n",
      "Epoch 387/400\n",
      "323/323 [==============================] - 0s 69us/step - loss: 1.9564 - mean_absolute_error: 1.0281 - val_loss: 12.4976 - val_mean_absolute_error: 2.3426\n",
      "Epoch 388/400\n",
      "323/323 [==============================] - 0s 68us/step - loss: 2.1043 - mean_absolute_error: 1.0555 - val_loss: 12.7458 - val_mean_absolute_error: 2.3836\n",
      "Epoch 389/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 1.8513 - mean_absolute_error: 0.9882 - val_loss: 12.1577 - val_mean_absolute_error: 2.2952\n",
      "Epoch 390/400\n",
      "323/323 [==============================] - 0s 78us/step - loss: 1.8232 - mean_absolute_error: 0.9695 - val_loss: 12.5917 - val_mean_absolute_error: 2.3239\n",
      "Epoch 391/400\n",
      "323/323 [==============================] - 0s 76us/step - loss: 1.7482 - mean_absolute_error: 0.9353 - val_loss: 12.2464 - val_mean_absolute_error: 2.3011\n",
      "Epoch 392/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 1.9315 - mean_absolute_error: 1.0065 - val_loss: 12.3461 - val_mean_absolute_error: 2.3182\n",
      "Epoch 393/400\n",
      "323/323 [==============================] - 0s 77us/step - loss: 1.8778 - mean_absolute_error: 1.0060 - val_loss: 12.9375 - val_mean_absolute_error: 2.3899\n",
      "Epoch 394/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 1.8078 - mean_absolute_error: 0.9646 - val_loss: 12.7573 - val_mean_absolute_error: 2.3800\n",
      "Epoch 395/400\n",
      "323/323 [==============================] - 0s 74us/step - loss: 1.8184 - mean_absolute_error: 0.9700 - val_loss: 12.7726 - val_mean_absolute_error: 2.3640\n",
      "Epoch 396/400\n",
      "323/323 [==============================] - 0s 81us/step - loss: 1.9026 - mean_absolute_error: 1.0058 - val_loss: 12.6510 - val_mean_absolute_error: 2.3536\n",
      "Epoch 397/400\n",
      "323/323 [==============================] - 0s 80us/step - loss: 1.8806 - mean_absolute_error: 0.9797 - val_loss: 12.5458 - val_mean_absolute_error: 2.3432\n",
      "Epoch 398/400\n",
      "323/323 [==============================] - 0s 83us/step - loss: 1.9078 - mean_absolute_error: 1.0080 - val_loss: 12.3540 - val_mean_absolute_error: 2.2965\n",
      "Epoch 399/400\n",
      "323/323 [==============================] - 0s 70us/step - loss: 2.0137 - mean_absolute_error: 1.0497 - val_loss: 12.6466 - val_mean_absolute_error: 2.3562\n",
      "Epoch 400/400\n",
      "323/323 [==============================] - 0s 88us/step - loss: 2.0770 - mean_absolute_error: 1.0731 - val_loss: 12.8355 - val_mean_absolute_error: 2.3866\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data, train_labels,epochs=400,validation_split=.2, verbose=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the held-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 86us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.286974738625918, 2.6441574470669615]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create learning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history1(history):\n",
    "  hist = pandas.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "  \n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MPG]')\n",
    "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
    "           label='Train loss')\n",
    "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
    "           label = 'Val Error')\n",
    "  plt.legend()\n",
    "  plt.xlim([0,200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4XNWZ5/HvW/um3bK8ryzGxsYYBwi7QxZIQugmJEAI0KEzdOhkEpLJJCSZmYY0Pc0wk0zI1hlIIJCkcUI20pCN0EkgQAPGGBvMYuNVtqxdKqmqVOuZP86VLBtJVZKqVCr5/TxPPa66VXXr1ZV8f3XOufdcMcaglFJKHc1V7gKUUkpNTxoQSimlRqQBoZRSakQaEEoppUakAaGUUmpEGhBKKaVGpAGhlFJqRBoQSimlRqQBoZRSakSechdQiFmzZpklS5aUuwyllKoozz//fIcxpnGi76+IgFiyZAmbNm0qdxlKKVVRRGTvZN6vXUxKKaVGpAGhlFJqRBoQSimlRlQRYxBKqZknnU7T3NzMwMBAuUupeIFAgAULFuD1eou6Xg0IpVRZNDc3U1VVxZIlSxCRcpdTsYwxdHZ20tzczNKlS4u6bu1iUkqVxcDAAA0NDRoOkyQiNDQ0lKQlpgGhlCobDYfiKNV2rIyASHSXuwKllDrmVEZAxDvLXYFSaobp7Oxk7dq1rF27ljlz5jB//vyhx6lUqqB1fOQjH+G1114r+DO/+93vctNNN0205ClXGYPUmWS5K1BKzTANDQ1s2bIFgFtuuYVIJMJnP/vZI15jjMEYg8s18nfpe++9t+R1llNltCCyaXtTSqkS27lzJytXruTqq69m1apVtLS0cMMNN7B+/XpWrVrFl7/85aHXnnPOOWzZsoVMJkNtbS0333wzp5xyCm9961tpa2sb83N2797Nhg0bWLNmDe94xztobm4GYOPGjZx88smccsopbNiwAYBt27bxlre8hbVr17JmzRp27dpVug0wTGW0IDDQux/ql5W7EKVUCdz6by+z/WC0qOtcOa+af7hk1YTe++qrr3L//fezfv16AG6//Xbq6+vJZDJs2LCByy+/nJUrVx7xnt7eXs4//3xuv/12PvOZz3DPPfdw8803j/oZf//3f89HP/pRrr76au666y5uuukmfvrTn3Lrrbfypz/9iaamJnp6egD49re/zWc/+1muuOIKkskkxpgJ/VzjVRktCICu3eWuQCl1jFi+fPlQOAA88MADrFu3jnXr1vHKK6+wffv2N70nGAxy8cUXA3DaaaexZ8+eMT/jmWee4corrwTg2muv5YknngDg7LPP5tprr+W73/0uuVwOgLPOOovbbruNO+64g/379xMIBIrxY+ZVIS0IoHtPuStQSpXIRL/pl0o4HB66v2PHDu68806effZZamtr+fCHPzziOQc+n2/ovtvtJpPJTOiz7777bp555hkefvhh1q1bxwsvvMA111zDW9/6Vh555BEuuugi7rnnHs4777wJrX88KqIFYRANCKVUWUSjUaqqqqiurqalpYXf/e53RVnvmWeeyU9+8hMAfvjDHw7t8Hft2sWZZ57JP/7jP1JXV8eBAwfYtWsXxx13HJ/61Kd473vfy9atW4tSQz4V0YJI4SXbtRt3uQtRSh1z1q1bx8qVK1mxYgWLFy/m7LPPLsp6v/Wtb3H99dfzz//8zzQ1NQ0dEfXpT3+a3bt3Y4zhne98JyeffDK33XYbDzzwAF6vl3nz5nHLLbcUpYZ8ZKoGOybjxHlV5sUvriHwiSfLXYpSqkheeeUVTjrppHKXMWOMtD1F5HljzPpR3pJXRXQxpYwXd88eqIAwU0qpmaIyAgIP3ky/TrmhlFJTqCICIudyjg7o1kNdlVJqqlREQODx23/1SCallJoyFREQbq9tQeR6D5a5EqWUOnZURED4vF4Sxkess7ncpSil1DGjIgLC73HRZmqJd2oLQilVHBs2bHjTSW9f+9rXuPHGG8d8XyQSGXG52+0emi587dq13H777UWrtVxKdqKciCwE7geaAAPcZYy5U0TqgR8DS4A9wAeNMWMenuT3ummjlgXRllKVq5Q6xlx11VVs3LiRd73rXUPLNm7cyB133DGh9QWDwaHpw0eTzWZxuw+f8pvJZPB48u+GC31dsZWyBZEB/osxZiVwJvBxEVkJ3Aw8Zow5HnjMeTwmj0topx5fYuzpc5VSqlCXX345jzzyyNDFgfbs2cPBgwc599xz6e/v58ILL2TdunWsXr2ahx56aMKfs2TJEj7/+c+zbt06HnzwQS644AJuuukm1q9fz5133smePXt429vexpo1a7jwwgvZt28fAH/zN3/Dxz72Mc444ww+97nPFeVnHq+SRZIxpgVoce73icgrwHzgUuAC52X3AX8CPp9vfXHfLEKpbSWpVSlVZr+5GQ4V+f/3nNVw8ejdPPX19Zx++un85je/4dJLL2Xjxo188IMfREQIBAL84he/oLq6mo6ODs4880ze9773jXnt50Qiwdq1a4cef+ELX+CKK64A7MWJNm/eDMB3vvMdUqkUmzZtAuCSSy7huuuu47rrruOee+7hk5/8JL/85S8BaG5u5qmnnjqi1TGVpqTNIiJLgFOBZ4AmJzwADmG7oPJKh2YTjMYgFQNfOP8blFIqj8FupsGA+N73vgfYK8l98Ytf5PHHH8flcnHgwAFaW1uZM2fOqOsaq4tpMChGevz000/z85//HIBrrrnmiNbCBz7wgbKFA0xBQIhIBPgZcJMxJjo8gY0xRkRGnD9DRG4AbgBYtGgRUjUHokDfIWhYXuqylVJTaYxv+qV06aWX8ulPf5rNmzcTj8c57bTTAPjRj35Ee3s7zz//PF6vlyVLlow4xXehhk8fPtLjQt831Up6FJOIeLHh8CNjzM+dxa0iMtd5fi4w4sCCMeYuY8x6Y8z6xsZGfLXzAEj36JFMSqniiEQibNiwgeuvv56rrrpqaHlvby+zZ8/G6/Xyxz/+kb1795ashrPOOouNGzcCNpjOPffckn3WeJUsIMQ2Fb4HvGKM+eqwp34FXOfcvw4oaPQnNGsBAL1tei6EUqp4rrrqKl588cUjAuLqq69m06ZNrF69mvvvv58VK1bkXc/gGMTgbazLjQ73jW98g3vvvZc1a9bwgx/8gDvvvHPCP0uxlWy6bxE5B3gC2AbknMVfxI5D/ARYBOzFHubaNda61q9fb75930ZOf/A0dp/2JZZeUp4RfaVU8eh038VVium+S3kU01+A0Yb8Lxzv+mbPnkPSeElpF5NSSk2JijiTGmBuXZA2U4uJHip3KUopdUyomIDwe9x0u+vxxFvLXYpSqkgq4YqWlaBU27FiAgKg3zuLYLKj3GUopYogEAjQ2dmpITFJxhg6OzsJBAJFX/fUT+4xCangbGp6x57rRClVGRYsWEBzczPt7e3lLqXiBQIBFixYUPT1VlRAUNVEpDeGScURX6jc1SilJsHr9bJ06dJyl6HGUFFdTJ6qRgB6unTSPqWUKrWKCgh/1SwAop06UK2UUqVWUQERrG4AoL9H+yyVUqrUKiogIvWzAUj06pFMSilVahUVEDV1NiBSfdqCUEqpUqusgHBaEJnYmFcoVUopVQQVFRAuf5gBfJjEmHP7KaWUKoKKCgiAfongSmgLQimlSq3iAiLhrsab6i13GUopNeNVXEAkvTUEMhoQSilVahUXEBl/LaFsX7nLUEqpGa/iAsIE6qihj3gqU+5SlFJqRqu4gJBwPbXE6Igmy12KUkrNaBUXEN5IPX5J0xnVcQillCqligsInbBPKaWmxpjXgxCR+gLWkTPG9BSpnrxCtXbK77jOx6SUUiWV74JBB52bjPEaN7CoaBXlEXECQifsU0qp0soXEK8YY04d6wUi8kIR68nL53QxZfo1IJRSqpTyjUG8tYB1FPKa4gnWAZCJ6XxMSilVSmO2IIwxA8Mfi8h8bJcSwEFjTObo15ScExCSmLJhD6WUOiblG6T+AuA1xnzZWfQ00AP4gPuAfy5teSPwBkmKH29KA0IppUopXxfTB4CvDHvcaYxZA6wC3lOyqvJIuKvx63xMSilVUnnPgzDGxIY9vNNZlgWCpSoqn6S3mpAGhFJKlVS+gIiIiHfwgTHm+wAi4geqS1jXmDLeGkK5OKlMrlwlKKXUjJcvIH4K/D8RCQ0uEJEw8B3nubLI+SNUSZzeRLpcJSil1IyXLyD+O9AG7BOR50VkM7AHaHWeKw9/FRESGhBKKVVC+Q5zzQI3i8itwHHO4p3GmETJKxuDO1BDUBLsTaTKWYZSSs1oY7YgROR4EXkIeA74ItBV7nAA8IRqqCJBT1xbEEopVSr5upjuAR4G3g9sBr5R8ooK4A3V4Jc00b5Y/hcrpZSakHxzMVUZY+527v9vZwyi7AKRWgBi/XqynFJKlUq+gAiIyKkcns01OPyxMaYsgeEP1wCQjGlAKKVUqeQLiEPAV0d5bIC3laKofFwBewpGSlsQSilVMvmOYrpgiuoYH38VAOmEnk2tlFKlkm+yvsvGet4Y8/Mx3nsP8F6gzRhzsrPsFuA/Ae3Oy75ojPn1eAoGwGlBZOPRcb9VKaVUYfJ1Mf0U2OLc4Mgryxlg1IAAvg98E7j/qOX/1xjzf8ZR45v5bUCYZN+kVqOUUmp0+QLiMuBKYA3wEPCAMWZnISs2xjwuIksmVd1onC4mktqCUEqpUhnzPAhjzC+NMVcC5wNvAF8Rkb+IyPmT+MxPiMhWEblHROpGe5GI3CAim0RkU3t7+5FPOgHhTvdPogyllFJjyTvdt2MA6AWiQAQITPDz/gVYDqwFWjjyWhNHMMbcZYxZb4xZ39jYeOSTngBZceNN95HLmQmWopRSaiz5Bqnfhu1iOh34A3CnMWbTRD/MGNM6bN13Y8/SHj8R0u4I4XSCvmSGmqA3/3uUUkqNS74xiD8AW4G/AH7gWhG5dvBJY8wnx/NhIjLXGNPiPPxr4KXxvH+4jK+KSDJBbzytAaGUUiWQLyCuxx6tNG4i8gBwATBLRJqBfwAuEJG1zjr3AH83kXUDGF/ETtiXSLGIUP43KKWUGpd8J8p9f6IrNsZcNcLi7010fW/iryJCTK8JoZRSJZJvuu9b8q2gkNeUgitQTUR0ym+llCqVfF1MHxWRsU42EOwg9i1Fq6hA7kA1VcTp0RaEUkqVRL6AuBuoKuA1U84TqiEiCWLJTDk+XimlZrx8YxC3TlUh4+UO2qvK9Q9oQCilVCkUeqLctCOBKgKSJh6Pl7sUpZSakSo2IAYn7EsldD4mpZQqhbwBISJuEfn0VBQzLs58TFkNCKWUKom8AWGMyQIjndNQXoMzug5oQCilVCnkO4pp0JMi8k3gx0BscGG5rkkNHA6IlF4TQimlSqHQgFjr/PvlYcvKdk1qYGgMAr1okFJKlURBAWGM2VDqQsbNCQhXSq8JoZRSpVDQUUwiUiMiXx28gI+IfEVEakpd3Jj8EQA8GW1BKKVUKRR6mOs9QB/wQecWBe4tVVEF8dmA8GfjpLO5spailFIzUaFjEMuNMe8f9vhWEdlSioIK5g1hEMIyQCyZoTbkK2s5Sik10xTagkiIyDmDD0TkbCBRmpIK5HKRcQcJM0CfTrehlFJFV2gL4mPA/cPGHbqB60pTUuGy3jDhpAaEUkqVQt6AEBEXcKIx5hQRqQYwxkyLs9Ny3ggRSdCvM7oqpVTRFXImdQ74nHM/Ol3CAQB/hBBJ+pN6TQillCq2Qscg/iAinxWRhSJSP3graWUFEJ9tQWgXk1JKFV+hYxBXOP9+fNgyAywrbjnj4wpECNOiXUxKKVUChY5BfNgY8+QU1DMu7kA1YbQFoZRSpVDoGMQ3p6CWcXMHIoQlqVeVU0qpEih0DOIxEXm/iEhJqxkn8VfpUUxKKVUihQbE3wEPAkkRiYpIn4iU/2gmn3MUUyJV7kqUUmrGKXQ216pSFzIhvjAAab1okFJKFd2YLQgR+fCw+2cf9dwnSlVUwZwZXTMDOuW3UkoVW74ups8Mu/+No567vsi1jJ/PNmxyCZ3yWymlii1fQMgo90d6PPWcFoTRq8oppVTR5QsIM8r9kR5PPWcMAr2qnFJKFV2+QeoVIrIV21pY7tzHeVzWs6iBoYsGSSpe5kKUUmrmyRcQJ01JFRPlt2MQ3myMTDaHx13oUbtKKaXyGTMgjDF7p6qQCXG6mCIyQL9eVU4ppYqqsr9yO11MIQaIJvRsaqWUKqYKD4jBFkSC3oReE0IppYpp3AEhInUisqYUxYyby03WY69LrQGhlFLFVVBAiMifRKTauUjQZuBuEflqaUsrjPFGCJMgOqABoZRSxVRoC6LGudToZcD9xpgzgLeXrqxx8Nspv7UFoZRSxVVoQHhEZC7wQeDhEtYzbuKvsi0IDQillCqqQgPiy8DvgDeMMc+JyDJgx1hvEJF7RKRNRF4atqxeRB4VkR3Ov3UTL91y+cNERMcglFKq2AoKCGPMg8aYNcaYG53Hu4wx78/ztu8DFx217GbgMWPM8cBjzuNJEX8VNS7tYlJKqWIrdJB6mYj8m4i0O62Ch5xWxKiMMY8DXUctvhS4z7l/H/BX4674aL4IYRkgqpcdVUqpoiq0i+lfgZ8Ac4F52KvLPTCBz2syxrQ49w8BTaO9UERuEJFNIrKpvb199DX6tItJKaVKodCACBljfmCMyTi3HwKByXywMcYwxoywxpi7jDHrjTHrGxsbR1+Rv4qg0UFqpZQqtjHnYnLOewD4jYjcDGzE7tSvAH49gc9rFZG5xpgW56iotgms40i+CEGToC+enPSqlFJKHZZvNtfnsYEweHGgvxv2nAG+MM7P+xVwHXC78+9D43z/mznTbaQSek0IpZQqpnyzuS4d7TkR8Y71XhF5ALgAmCUizcA/YIPhJyLyt8Be7HkVkxOotv8mezHGIFL+C90ppdRMkK8FcQSxe9+3AR8C3ssYg8zGmKtGeerC8XxmXkF7KkUo108inSXkG9ePpJRSahSFHuZ6poh8Hfut/yHgcWBFKQsrWKAWgBpiOuW3UkoV0ZgBISL/U0R2AP8EbAVOBdqNMfcZY7qnosC8gjYgaqVfD3VVSqkiytcf81HgdeBfgH8zxiRFZNRDU8vC6WKqkZgGhFJKFVG+Lqa5wG3AJcAbIvIDICgi06ej3+liqiam50IopVQR5TuKKQv8FvitiPixA9NB4ICIPGaM+dAU1Dg2fzUGoVZbEEopVVQFtwSMMUngZ8DPRKSaYsyjVAwuFyZQS01/TC8apJRSRTSha1IbY6LGmPuLXcxESbBWxyCUUqrIJhQQ040E62hwaUAopVQxzYiAIFhLnSuu50EopVQRFTwGISJnAUuGv2fadDMFaqmRV7UFoZRSRVRQQDiHty4HtgBZZ7EBpkdABOuooZ+eeKrclSil1IxRaAtiPbDSuYbD9BOsJZTrpy06UO5KlFJqxih0DOIlYE4pC5mUQC1ucsT6u5muGaaUUpWm0BbELGC7iDwLDF2ZxxjzvpJUNV7OdBvBTB/RgQw1wTFnIldKKVWAQgPillIWMWnBwzO6tvcNaEAopVQRFBQQxpg/l7qQSRmcj0litEaTHDe7qswFKaVU5RvP9SCeE5F+EUmJSFZEoqUurmBOF1Mt/bT16UC1UkoVQ6GD1N8ErgJ2YCfr+yjwrVIVNW6DXUwSoy2azPNipZRShSj4TGpjzE7AbYzJGmPuBS4qXVnj5HQxNbrjtGpAKKVUURQ6SB0XER+wRUTuAFqYTtN0+MLg8jLXO8BT2sWklFJFUehO/hrntZ8AYsBC4P2lKmrcRCBYS6M3oV1MSilVJIUexbRXRILAXGPMrSWuaWICtcxKxnWQWimliqTQo5guwc7D9Fvn8VoR+VUpCxu3YB210k9bX1LPplZKqSIotIvpFuB0oAfAGLMFWFqimiameh51mXbiqSz9SZ32WymlJqvQgEgbY3qPWja9vqbXLqQqeQghR1ufjkMopdRkFRoQL4vIhwC3iBwvIt8AniphXeNXswh3LsUsorTqrK5KKTVphQbEfwZWYSfqewCIAjeVqqgJqV0IwHzpoF1bEEopNWmFHsUUB77k3KanGhsQC1zt7OmIl7kYpZSqfGMGRL4jlabNdN8w1IJYHY6yueXo4RKllFLjla8F8VZgP7Zb6RlASl7RRAVqIFDDCn8PPzg4feYRVEqpSpUvIOYA78BO1Pch4BHgAWPMy6UubEJqFrE43Ulzd4LeeJqakF4XQimlJmrMQWpnYr7fGmOuA84EdgJ/EpFPTEl141W7kMZsGwAvazeTUkpNSt6jmETELyKXAT8EPg58HfhFqQubkNpFhOIHAMN27WZSSqlJyTdIfT9wMvBr4FZjzEtTUtVE1SxE0jFOqMrwsgaEUkpNSr4xiA9jZ2/9FPBJkaExagGMMaa6hLWNn3Mk09mz4jx5ULuYlFJqMsYMCGPM9LnmQyGccyHWVvdx355+EqksQZ+7zEUppVRlqqwAyKfezh+4yt9KzsCLzT1lLkgppSpXWQJCRPaIyDYR2SIim4q24mAdNK5gcf+LiMBzu7uKtmqllDrWlLMFscEYs9YYs76oa118Nt7m/+Ck2SGe3aMBoZRSEzWzupgAlpwNqX7e19TB5r3dZLK5cleklFIVqVwBYYDfi8jzInJDUde8+BwAzvW9RiyV5ZWWvqKuXimljhXlCohzjDHrgIuBj4vIeUe/QERuEJFNIrKpvb298DVXNUHDcSyPbQHQbiallJqgsgSEMeaA828b9qzs00d4zV3GmPXGmPWNjY3j+4DFZxM4+CyL63w8u7uzGCUrpdQxZ8oDQkTCIlI1eB94J1DcM7SXb4BkL9fM2c+TOztJZrJFXb1SSh0LytGCaAL+IiIvAs8CjxhjflvUTzjhYgjU8N7cv9OfzPDUTm1FKKXUeE15QBhjdhljTnFuq4wx/1T0D/EGYPUHaDrwKHP9SX738qGif4RSSs10M+8w10GnfhjJDPCpOVt5dHsr2Zwpd0VKKVVRZm5AzF0LTSfznvhD9MViPL+3u9wVKaVURZm5ASECb7+Fqr5dfNL3b2x8bl+5K1JKqYoycwMC4Ph3wOoPcKP7l7z24tMc6EmUuyKllKoYMzsgAC66HYL1fNdzBz9/7MlyV6OUUhVj5gdEeBbu635JtSfDZVs/RucLvwKjA9ZKKZXPzA8IgKZV9Fz2YzK4aXjoGnL/7zx48uvQvAmS/eWuTimlpqV8lxydMeavOovfXvYo3/nJ17ix5y8sevS/2yfEBfNPg+PfBSdfBg3Ly1uoUkpNE8dMQABcdMoiXmu/kfP+cCGXLsly25mGqq5t8MYf4Y+32VvDcbDkHDsr7KIz7GVMD1+LWymljhliKqA/fv369WbTpuJdeO4nm/bzpV9sI+h18/ENx/HX6+YzO9cJ2x+C3X+GvU9BMmpf7K+xczutuQKOezt4fEWrQymlSklEnp/MRdmOyYAAeL21j9seeYXHX29HBM49vpH/9p6TOKGpCnJZOLQVDmyGli3w6iMQ77SXNF1yDgTrYc5qWLYB6peB69gYylFKVRYNiEl6pSXK714+xL1P7qE/meEDpy3gxguWs7ghfPhF2bTthtr6Yxsc8U57A/AE7RjGW/4WFrwFPAHw+MEXBpe7JDUrpVQhNCCKpCuW4s4/vM4Dz+0nnc1x/gmNnH9CIx63C7cIkYCHt62YTcTvsYfJdu2CPX+B9tfgtUege8+RK/TXwIkXwbx1EJ4FuQwgEGqAdBz6WiB60C5vXAGdO2H/M/b1J10CC0/XgFFKTYoGRJG1RQe4/+m9PPj8flqjySOeq/J7uPL0hXzs/OU0RPyHn8hl7dhF7wHIDEAmCW3b4bVfQ2KMOaBcXhsCmQFweaBpFbS9AtkUhGfDvLUQqIWBHrvO2oW2e8vjB7ffjod4Arbrq3oeVM+3z7W9Aq0vQ9cbMH89rHgPhOptsCWj4KuafLdYLge9+2yw1S+zt0zK/ryZhA3PfU/bbROZbbvjGk+0Aenx51+/UmrSNCBKJJsz9MRTZI0hmzM0dyf4wdN7eXjrQYJeN+9Y2cTpSxt4z+q51IS8I68kl4NEF8Q67M7cGHvfG4CqeXZniYGu3RBusDv6gSjs+L0Nl86ddocbrAO3D3r2w0CvDRQK+L35qiDlXJPbG7I762zShkrdUrtTx9jWT7IP0onDYRWqt8tSMbtjb1wBkSbob7UB1PG6bQkNCjfabjeTO7ws1ADesG0t5dJ2mbhh8Vl2DGcg6oSdD/Y9ZbdN0yp7JFmwzn5Oogvql4M3aD8v5XxmeJZ9HG2xIRuotYcoi8sGau1iG5qxDvvZnqB9jy8C0Wa7Lftb7WfVL4OevbYetw9OvBjqFhf+x5JJ2pvbZ3+34GzrlK17ooyxP0u8y9bu8kBvM4Rm2b8XpfLQgJhiO9v6+fafdvLEjg7a+5IEvC4uOGE2JzRFWD47wrJZEZY1hgn7S3gEsTG2a2qwtRLvsju96EG7A529Amavsjv5A5thz+N2Rykuu6Ppb7Oh1PWGXV/9MruD9QbsjjSbsjtmf5UNk7bt0LnL7ugjs21YzD7JBkf9cvv8wS1Qs8BeE9zlhbmn2JuIDZm9T9sWR/ce2PEodO+FYK0NpVQMFqy3LaDWl+1r0jGoWWR3hF27IJuxO1tfyGZjrM2GXvU8G0rxTrvDB/tzDg+q0XgCTtgeRdyw4t02ZOJd9udLRiE9YFtH6QEbtOK2P182dfi9g62p/c9BstduT5cH3F6YczJE5tjQzybtz5Rzfq66JfbnyQxA9AD07LMhlo6NXHv1AtvCrF1s1zEYwFXzINJoPzPaAu2v2m7QbMq2JE++DJpOPnzodqzD3kzWbrNEN7Rut3X4ws6Xh6htic463tboC9ubN2QD1z3K33ouZ2vTI//KRgOiTIwxbG+J8qNn9vHkzg72d8UZfsmJhrCP+rCP45sirF1Yy+KGMMsbIyxvDCOVel6FMVNzTogxdgc13m/fA1Fbnzdsw6i/zbZsPH4bnP2tttVRPd921/ki0L3b7ozrltpAjXfCf3wHXn3Y3vdFbKsm1HA4QL0B28VncnbH6q+2n5FOwMEXbKAtPN21H1B/AAASLUlEQVTu9ONd9nXpOLS8aB8Ha+3O1eWxt2SfbcFkUnZnWz0fahfZc3BqFti6BltCNQuh75BdV8uL9kuB22NDGXP44IlBtYttoGeTsPsJW2/9MtsajHfaluBY3H77exjoGeM1PicsXXb7i9N9mXRarw3Hwdw1djuC/V14/DaMOl53AioHyy6wP2/nTlhwOqz6Kxus/e3Q8drh9YVn2y8ikSb7dzK4jQeFG8EfObLGjp3w0k/t59YstL+fYL19fzruhP+A/dKQjsMTX7EHpmSTTuv0ODj+7XDSpU5L1fl/kMvZLyu9zfb3FmmCp78Bu/4Ea6+GlX81eoCWmjGIy6UBMR0kM1n2dsbZ1d7PG+0xDvQk6OhLsr0lSnP34Vlk59cGWTGnioaIj4aIn4awj1kRP0GfG49LaIj4WVwfoi6s37rUBKQTdsefy9gdpW/Y0XixDnuuz84/QKrfBumiM2yIiMt21fkitnXoi9jXhBvtc5077U4wHbctvlTsyPsma4PdGMD51x8BxLYKD22zoQ2HW3jekN3xVs2xO+e9TzvdgU7LzldlH4/UyssnWGfDzRey4X7g+cJalYN8VbD6cgjU2O3Z+jIc3Oysu95ul8yADets8vDPVbfEfkEIN0Ks3f57wkU2ODx+24If6LWttLZX7LoXrLfhGay3YZKK21arNwRLz7OH2b/6sD2asma+XZ+/6vC4ZH+bbZXnMjZQu/cMfVGQW6MaENNddyxFc3eCbQd6eWJHO/u64nT2p+iMJUln37z93S5hw4mzOW1xHWG/m6DXTW3Ix9JZYRY3hPC69bwLVYGSfbbF5A3aMRrkyIMlBqI2dMKzYeej8NpvbMhUzbPdmcE6+7pYu+3u7DtkwyTUYNcLNgT6W203XTZtP7PvkN0Jn/VJG5idO2D/s/azPEFbjzfotAKdbsQV77Utt+G698Ib/26DYnC8qmqObe1Vz7fL3/gjnPphWHcdvP4b2PYg7HzMhu3wgKqeD7NX2tbkvmcOh+egSJMzLhi3QbH6cvvzt263B8RkU7bVmEvb7bjwDLuuzIAN/MhsyKaRd35ZA6JSGWOIDmTo6E+STOdIZ3N0xpI8u7ubn21upr0v+ab3uF3CovoQy2aFWTorzPy6IPNqg8yrCRLwuvB73DREfIR87srtylJqJsqkIN5hw2gw7AZl07ZlkcvY4AnV25ZE83N2zGj4QQnZtNONJzYoPYFRD1rQMYgZyhhDIp0lnsqSSGXp6E+yuyPGrvYYuzr62dUeY09njIH0yM3mgNdFQ9jPrGFdWQ0RP/VhL5mcwRiYXeVnfm2QubVB6sM+qgMeDRWlZpDJBsQxNVlfJRERQj4PIZ/9FS2sD3HqoiO/dRhj6IqlONCToKV3gFQmx0A6S1csRWcsRUd/ks7+FG19A2w/GB21S2uQ2yXUBr3UhrzUh300VvlpCNvxkSq/h6bqAJmcITqQJppIY4DaoJe6kI/akJfakI8651+3S0hmsnT2p4bqz+YMfQNpgj43dSHfiF1lmWwOt0s0qJSaBjQgKpiIHdRuiPhZsyD/640x9CczQzvm1uiADZeeAbpiKbrjKbrjaXri9v5rh/rojHUykM6+qaXicQkijBk4Y3EJzK8LsqQhzIK6IH6Pm31dcZ7c2UF92Mf5JzSSM4ZsDpqq/cytCdBUHWBuTZCGiA2Xlt4Eb7T3E/C4qQl5qQl6aXS2h9ulAaPUZGlAHENEhKrA4ZP6FjeEj5xzagwD6Sxt0SRej1AT9BL02mlAYqks3bEUvYn0UMD0xlPkDHjcQkPYhzHQ3J3A47afn0hlaOtLsrczzt7OGI+2RElnDXUhL1e8ZSEtvQM8sq2FkM+NW4S2viSZXOFBJAIuEXLGdqX53C7CfjcL60OEfR5eb+1DRFjWGCbkc+MSwSUwK+LnhKYqgj63PSAH4/wLGIPLZeuvDnioCXqJ+D2E/R7CPg9utzCQznKod4B9XXH2d8UJ+T2846Qm5tQExvNrKpp0NsdLB3o5aW41Aa9O26LGT8cg1LSXyxk6YkkO9Q5wqNe2dlLZnLNDj5DKGHoTtuXT0Z+krS9JzhhcIgiQytqurX1dcaIDGU5simAM7OmMkcrknLPloaU3QU88XfT6qwMe6sI+3GJbXeLU5XG7mFPtpyrgJZnJksrkSA7dsiTTOaoCHurDPqIDGVKZHGG/m6aqAAvqQwS9bgyGRCpLLJllIJPF73ER9NpDpn+55SD7uuLUhbysXVjLtgNRFtQFef+6+bx6qI/2viQXr55DYyTAwd4EJ82pZuW8alwCB3ttt6Tf46Kxys/ihtBQd2ehBg/CqAmOMtOAKjkdpFaqSIwxdMZSpLM5BGdnDiAg2BZJNJEmOpCmN5EmlswSS2aIpbJkczn8HjdN1X4W1odYWB+iLZrkj6+20dwdpzueti0a53OMgVQmx6HoALFkhoDXjd9jj0LzeVz4PS58HhfRgTRdsTTVAQ8+j4tYMkNL7wAtvYfPDRCBsM+D3+MilckRT2fJ5gyr59dw1emL+PPrbexo6+eUBbW8uL+HXR0xQj43NUHvEesB2/XncblIZd988ENVwEPE7yHkcw+1ntLZHD1xO65UH/axqD5EbchHLJnh99sPsb8rweKGEMfPjhDyeZhTE2BWxEcilSPgdbGgLkQyk6U1muSN9n4ifg+XrZvPssYImWyO3R0x+pMZaoM+aoJeROClA70MZLKsWVA71D052u/TGHC5hFQmR1csRVO1v6DxrR2tfexo6+f8ExpLOytCiWlAKHUMymRzQ+M/Aa/rTTu9dDY34kEAuZxhZ3s/i+pD+NwuXtjfTTKTY051gG0Henm9tY9MzjC3OsDqBbXkjKE1OsDu9hidsRSxZIZ4Kkt/MkMsmcHjFmqDPgYyWdr7kuzrjNOfyuBxCWcsbeD0pfW8dKCX5u4EsVRm6GCKkTRW+elNpEd9fjQRv4e6sJeQ10MmlyPoc+Nzu9jdEaMnkabK76E/mSFnoD7s44SmCF63C5cIXrcQ8XtoiPhZVB8iZwxbm3t5aMsBcgbCPjdnLmtg+ewIYZ8Hj9u+pz7sZ15NAL/XRX8yy47WPvweF8tnR+iOpTnYk6A3kaaxys8Zy+oRhHQ2x5JZYbpjKTbv62Z+bZA5NQFe2NdDyOfmvBMah35nqUyO3kSa3kSKzv4U8VSWxio/HrfQHUvTELFhnK/rUI9iUuoY5HG7GOWLM8CoJ1O6XGIviuU4bfHhk8GWNUZGektR5XKG/lSGkNdNPJ2luStBwGu7saoCXnoTaR7d3kpXLIlLhMUNYWpDXnrjaXoSaZKZLCvnVhPyedja3GO7HOMpumN2J+pxC4mUPajiopPn0BD2Ex1IUxu0R+ZtOxBlb2eMZCZDLmdIZ+2BG+19SRLpLAB+j4uPnL2UDSfO5uGtB9myv4fHd7SP+4AMl8A4hs6oCXoJ+dz0xNNDtYxFBObV2JCJ+G3rzuMWWnoHcAmsnFszrnpHogGhlJoyLpdQ7RwoUe12sXLekeMTNUEvl59WwCF5wIlzqvK/qEDGGNr7k7hFqAv5cDlHwZ1z/Kyh12RzhnTWntA6eHh5Jmvwe1wcNztCMpPjjfZ+GsJ+5tcFqQ542N+V4Pl9XfjcbtwueKM9RsTvYf2SOg72DNDSm+CUBbV09Cf57UuHhrZBjXO4eXXQS0PYT8jvpi2aJJuzB3O09yfZ0xFnd0c/bX1JeuIpmrvjpLI55lYHGcjk+Ndn9056u2gXk1JKzUDGGFyTnKxPJ/VRSqkZqBgnm2pAKKWUGpEGhFJKqRFpQCillBqRBoRSSqkRaUAopZQakQaEUkqpEWlAKKWUGlFZAkJELhKR10Rkp4jcXI4alFJKjW3KA0JE3MC3gIuBlcBVIrJyqutQSik1tnK0IE4HdhpjdhljUsBG4NIy1KGUUmoM5QiI+cD+YY+bnWVKKaWmkWk7SC0iN4jIJhHZ1N7eXu5ylFLqmFOO6b4PAAuHPV7gLDuCMeYu4C4AEekTkdemprxJmQV0lLuIAmidxVMJNYLWWWyVUueJk3lzOQLiOeB4EVmKDYYrgQ/lec9rk5mydqqIyCats3gqoc5KqBG0zmKrpDon8/4pDwhjTEZEPgH8DnAD9xhjXp7qOpRSSo2tLFeUM8b8Gvh1OT5bKaVUYabtIPVR7ip3AQXSOourEuqshBpB6yy2Y6LOirjkqFJKqalXKS0IpZRSU2xaB8R0nbNJRBaKyB9FZLuIvCwin3KW3yIiB0Rki3N79zSodY+IbHPq2eQsqxeRR0Vkh/NvXZlrPHHYNtsiIlERuWk6bE8RuUdE2kTkpWHLRtx+Yn3d+XvdKiLrylzn/xaRV51afiEitc7yJSKSGLZdv1PmOkf9PYvIF5zt+ZqIvKuMNf54WH17RGSLs7yc23K0/VDx/j6NMdPyhj3C6Q1gGeADXgRWlrsup7a5wDrnfhXwOnZeqVuAz5a7vqNq3QPMOmrZHcDNzv2bgf9V7jqP+r0fAhZPh+0JnAesA17Kt/2AdwO/AQQ4E3imzHW+E/A49//XsDqXDH/dNNieI/6enf9TLwJ+YKmzP3CXo8ajnv8K8D+mwbYcbT9UtL/P6dyCmLZzNhljWowxm537fcArVNZ0IZcC9zn37wP+qoy1HO1C4A1jzN5yFwJgjHkc6Dpq8Wjb71LgfmP9B1ArInPLVacx5vfGmIzz8D+wJ6WW1SjbczSXAhuNMUljzG5gJ3a/UFJj1SgiAnwQeKDUdeQzxn6oaH+f0zkgKmLOJhFZApwKPOMs+oTTfLun3F03DgP8XkSeF5EbnGVNxpgW5/4hoKk8pY3oSo78zzfdtieMvv2m89/s9dhvj4OWisgLIvJnETm3XEUNM9LveTpuz3OBVmPMjmHLyr4tj9oPFe3vczoHxLQnIhHgZ8BNxpgo8C/AcmAt0IJtipbbOcaYddjp1T8uIucNf9LYtue0OJRNRHzA+4AHnUXTcXseYTptv9GIyJeADPAjZ1ELsMgYcyrwGeBfRaS6XPVRAb/nYa7iyC8wZd+WI+yHhkz273M6B0RBczaVi4h4sb+UHxljfg5gjGk1xmSNMTngbqagOZyPMeaA828b8AtsTa2DTUvn37byVXiEi4HNxphWmJ7b0zHa9pt2f7Mi8jfAe4GrnZ0FTpdNp3P/eWzf/gnlqnGM3/O02p4i4gEuA348uKzc23Kk/RBF/PuczgExNGeT883ySuBXZa4JGOqH/B7wijHmq8OWD+/P+2vgpaPfO5VEJCwiVYP3sYOWL2G343XOy64DHipPhW9yxLez6bY9hxlt+/0KuNY5WuRMoHdYU3/KichFwOeA9xlj4sOWN4q9cBcisgw4HthVnirH/D3/CrhSRPxi5247Hnh2qusb5u3Aq8aY5sEF5dyWo+2HKObfZzlG38cxSv9u7Mj8G8CXyl3PsLrOwTbbtgJbnNu7gR8A25zlvwLmlrnOZdijQF4EXh7chkAD8BiwA/gDUD8NtmkY6ARqhi0r+/bEBlYLkMb22f7taNsPe3TIt5y/123A+jLXuRPb5zz4N/od57Xvd/4etgCbgUvKXOeov2fgS872fA24uFw1Osu/D3zsqNeWc1uOth8q2t+nnkmtlFJqRNO5i0kppVQZaUAopZQakQaEUkqpEWlAKKWUGpEGhFJKqRFpQCgFiEhWjpxRtmizBzszfk6XcziUKlhZLjmq1DSUMMasLXcRSk0n2oJQagzO3P93iL2mxrMicpyzfImI/LszwdxjIrLIWd4k9toLLzq3s5xVuUXkbmfe/t+LSLBsP5RSBdKAUMoKHtXFdMWw53qNMauBbwJfc5Z9A7jPGLMGOwne153lXwf+bIw5BXtNgZed5ccD3zLGrAJ6sGfgKjWt6ZnUSgEi0m+MiYywfA/wNmPMLmditEPGmAYR6cBOCZF2lrcYY2aJSDuwwBiTHLaOJcCjxpjjncefB7zGmNtK/5MpNXHaglAqPzPK/fFIDrufRcf/VAXQgFAqvyuG/fu0c/8p7AzDAFcDTzj3HwNuBBARt4jUTFWRShWbfotRygqKcyF6x2+NMYOHutaJyFZsK+AqZ9l/Bu4Vkf8KtAMfcZZ/CrhLRP4W21K4ETszqFIVR8cglBqDMwax3hjTUe5alJpq2sWklFJqRNqCUEopNSJtQSillBqRBoRSSqkRaUAopZQakQaEUkqpEWlAKKWUGpEGhFJKqRH9f47NrBgG72zlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history1(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history2(history):\n",
    "  hist = pandas.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "  \n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('loss')\n",
    "  plt.plot(hist['epoch'], hist['loss'],\n",
    "           label='Train loss')\n",
    "  plt.plot(hist['epoch'], hist['val_loss'],\n",
    "           label = 'Val loss')\n",
    "  plt.legend()\n",
    "  plt.xlim([0,200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XuUHHWd9/H3t29z6Z5kMskQLgETLqtySwwBgwhsRBF40OjKIlmU+3JWXQ/I4srqnmdxlz0inme9POvqg4gLigRW5cADKiLigo8KBgx3WGJINokh95nJ3Pr6ff6ompmeYTLMpWt6uvN5ndOnq35dVf3t6pn69K+qu8rcHRERkfGKVbsAERGpLQoOERGZEAWHiIhMiIJDREQmRMEhIiITouAQEZEJUXCIiMiEKDhERGRCFBwiIjIhiWoXMBXz5s3zhQsXVrsMEZGa8uSTT+509/bJzl/TwbFw4ULWrFlT7TJERGqKmW2cyvzaVSUiIhOi4BARkQlRcIiIyITU9DEOEak/+XyezZs309/fX+1Sal5jYyMLFiwgmUxWdLkKDhGZUTZv3kxLSwsLFy7EzKpdTs1yd3bt2sXmzZtZtGhRRZetXVUiMqP09/czd+5chcYUmRlz586NpOem4BCRGUehURlRrcfaDo6eHdWuQERkv1PjwbGz2hWISJ3ZtWsXS5YsYcmSJRx44IEccsghg+O5XG5cy7j00kt5+eWXx/2ct9xyC1dfffVkS552tX1wvFSodgUiUmfmzp3L2rVrAbj++uvJZDJce+21w6Zxd9ydWGz0z97f+c53Iq+zmmq7x1EqBjcRkYitW7eOo48+mgsvvJBjjjmGrVu3cuWVV7Js2TKOOeYY/vEf/3Fw2ne+852sXbuWQqFAa2sr1113HYsXL+bkk09m+/btYz7Pq6++yooVKzj++ON5z3vew+bNmwFYvXo1xx57LIsXL2bFihUAPPvss5x44oksWbKE448/nvXr10e3AsrUdo8Dh749kJ5X7UJEJAKf/7/P88Ifuyq6zKMPnsU/vO+YSc370ksvcfvtt7Ns2TIAbrzxRtra2igUCqxYsYLzzjuPo48+etg8nZ2dnH766dx4441cc8013HrrrVx33XX7fI6Pf/zjXHHFFVx44YXcfPPNXH311fzgBz/g85//PL/85S+ZP38+HR0dAPzbv/0b1157LR/+8IfJZrO4+6Re10TVdo8DoHdXtSsQkf3EEUccMRgaAHfeeSdLly5l6dKlvPjii7zwwguvm6epqYmzzz4bgBNOOIENGzaM+RyPP/44F1xwAQAXXXQRjz32GACnnHIKF110EbfccgulUgmAd7zjHdxwww3cdNNNbNq0icbGxkq8zDdU4z0OggPk7W+udhUiEoHJ9gyikk6nB4dfeeUVvvrVr/LEE0/Q2trKRz7ykVF/M5FKpQaH4/E4hcLkjs1+61vf4vHHH+f+++9n6dKl/P73v+ejH/0oJ598Mg888ABnnXUWt956K6eddtqklj8R6nGIiExCV1cXLS0tzJo1i61bt/Lggw9WZLnLly/n7rvvBuB73/veYBCsX7+e5cuX80//9E/MmTOHLVu2sH79eo488kiuuuoqzj33XJ555pmK1PBGar/HoeAQkSpYunQpRx99NG95y1t405vexCmnnFKR5X7961/nsssu4wtf+ALz588f/IbWpz71KV599VXcnTPPPJNjjz2WG264gTvvvJNkMsnBBx/M9ddfX5Ea3ohN18GUKCw7OO5rVn8RTrv2jScWkZrw4osv8ta3vrXaZdSN0danmT3p7sv2McsbquldVSVi5Pfq1+MiItOppoOjQJxsl4JDRGQ61XhwxCh067QjIiLTqaaDo0hc56sSEZlmNR0cBeLE+3dXuwwRkf1KTQdHkRgNuY5qlyEisl+p6eBwS5Aq9UG+r9qliEidWLFixet+zPeVr3yFj33sY2POl8lkJtRey2o7OGLh7xf1I0ARqZBVq1axevXqYW2rV69m1apVVapo5qnp4CAWD+4VHCJSIeeddx4PPPDA4EWbNmzYwB//+EdOPfVUuru7OeOMM1i6dCnHHXcc995777iX6+58+tOf5thjj+W4447jrrvuAmDr1q2cdtppLFmyhGOPPZbHHnuMYrHIJZdcMjjtl7/85Uhe62TV9ClHLJYMBhQcIvXpJ9fBa89WdpkHHgdn37jPh9va2jjppJP4yU9+wsqVK1m9ejXnn38+ZkZjYyP33HMPs2bNYufOnSxfvpz3v//947q2949+9CPWrl3L008/zc6dOznxxBM57bTT+P73v8973/tePve5z1EsFunt7WXt2rVs2bKF5557DmDwNOozRU33OGLxIPcK+vW4iFRQ+e6q8t1U7s5nP/tZjj/+eN797nezZcsWtm3bNq5l/upXv2LVqlXE43Hmz5/P6aefzu9+9ztOPPFEvvOd73D99dfz7LPP0tLSwuGHH8769ev55Cc/yU9/+lNmzZoV2WudjEh7HGa2AdgLFIGCuy8zszbgLmAhsAE43933WBDZXwXOAXqBS9z9qbGWH0sEPY7uPdtpjeg1iEgVjdEziNLKlSv51Kc+xVNPPUVvby8nnHACAHfccQc7duzgySefJJlMsnDhwlFPpT4Rp512Go8++igPPPAAl1xyCddccw0XXXQRTz/9NA8++CDf/OY3ufvuu7n11lsr8dIqYjp6HCvcfUnZCbWuAx5296OAh8NxgLOBo8LblcA33mjBiUSCkht9nWNfilFEZCIymQwrVqzgsssuG3ZQvLOzkwMOOIBkMskjjzzCxo0bx73MU089lbvuuotisciOHTt49NFHOemkk9i4cSPz58/nL//yL7niiit46qmn2LlzJ6VSiQ996EPccMMNPPXUmJ+hp101jnGsBP40HL4N+CXwmbD9dg9O1/tbM2s1s4Pcfeu+FpSIxdhLE7nuPRGXLCL7m1WrVvHBD35w2DesLrzwQt73vvdx3HHHsWzZMt7ylreMe3kf/OAH+c1vfsPixYsxM2666SYOPPBAbrvtNr70pS+RTCbJZDLcfvvtbNmyhUsvvXTwSn9f+MIXKv76piLS06qb2avAHsCB/+PuN5tZh7u3ho8bsMfdW83sfuBGd/9V+NjDwGfcfc2+lr/4bSf4/e/rJLfg7Rxx5R2RvQ4RmT46rXplRXFa9ah7HO909y1mdgDwkJm9VP6gu7uZTSi5zOxKgl1ZHHbYYXTSSlPfzPrGgYhIPYv0GIe7bwnvtwP3ACcB28zsIIDwfuAAxRbg0LLZF4RtI5d5s7svc/dl7e3t9MbSxHNdUb4MEREpE1lwmFnazFoGhoEzgeeA+4CLw8kuBgZ+QXMfcJEFlgOdYx3fGNCfmEUqr+AQqSe1fGXSmSSq9Rjlrqr5wD3hD2MSwPfd/adm9jvgbjO7HNgInB9O/2OCr+KuI/g67qXjeZJCsoWG7CuVrl1EqqSxsZFdu3Yxd+7ccf2wTkbn7uzatYvGxsaKLzuy4HD39cDiUdp3AWeM0u7AJyb6PIXULNJ9eydVo4jMPAsWLGDz5s3s2KEf9k5VY2MjCxYsqPhya/qUIwA0ttLYmYVCDhKpalcjIlOUTCZZtGhRtcuQMdT0KUcArCn4zbj3d1a5EhGR/UPNB0ciPQeA7g5dQlZEZDrUfHA0ZILg6OrUGXJFRKZDzQdHY8tcAHo7dSBNRGQ61HxwpGe3AdDXpfNViYhMh5oPjkxrOwD57t1VrkREZP9Q88Exp20eAPkena9KRGQ61HxwNDWlyXmCUr+CQ0RkOtR8cFgsxl7LYDpDrojItKj54ADojWV0hlwRkWlSF8HRn2ghqTPkiohMi7oIjnyyhcZid7XLEBHZL9RFcBRTs2ku6gy5IiLToS6Cwxtnk6GHbKFY7VJEROpeXQRHrLmV2fTQ0ZOrdikiInWvLoIj3jSHhJXY06mv5IqIRK0ugiMZnlq9V2fIFRGJXF0ERyo8tXr/XgWHiEjU6iI4GtOzAcj26LccIiJRq4vgaG4JLh+b7VVwiIhErS6CoykT9DgKCg4RkcjVRXDEG1sAKPQrOEREolYXwUFDEBzer1+Pi4hErT6CI5UJ7rM6X5WISNTqIzgSKXIkieUVHCIiUYs8OMwsbma/N7P7w/FFZva4ma0zs7vMLBW2N4Tj68LHF07kebKxZgWHiMg0mI4ex1XAi2XjXwS+7O5HAnuAy8P2y4E9YfuXw+nGLRdvJlHorUC5IiIylkiDw8wWAP8DuCUcN+BdwA/CSW4DPhAOrwzHCR8/I5x+XAqJNKliTyXKFhGRMUTd4/gK8LdAKRyfC3S4eyEc3wwcEg4fAmwCCB/vDKcfl2IyTWOpj3yx9MYTi4jIpEUWHGZ2LrDd3Z+s8HKvNLM1ZrZmx44dg+2lZIa09bG3vzDG3CIiMlVR9jhOAd5vZhuA1QS7qL4KtJpZIpxmAbAlHN4CHAoQPj4beN1ZC939Zndf5u7L2tvbhx5oyJChn66+fDSvRkREgAiDw93/zt0XuPtC4ALgF+5+IfAIcF442cXAveHwfeE44eO/cHcf7/NZQwsZ66NTwSEiEqlq/I7jM8A1ZraO4BjGt8P2bwNzw/ZrgOsmstB4Ywtp+unqV3CIiEQp8caTTJ27/xL4ZTi8HjhplGn6gT+f7HMkmmaRpp/OXl0+VkQkSvXxy3EglZ5FzJzebp2vSkQkSnUTHAMXc+rv0XXHRUSiVDfBkWyaBUC/rgIoIhKpugkOC0+tnu/trHIlIiL1rW6Cg4bg1OqFPh3jEBGJUv0ER3hNjpKuAigiEqn6CY6BqwDqYk4iIpGqn+AIexyW064qEZEo1U9whMc44nmdWl1EJEr1ExzJNACJoi7mJCISpfoJjliMbDxNQ7GXUmnc50YUEZEJqp/gAArxZtL00ZPTNTlERKJSX8GRTJOxPrqzCg4RkajUVXCUksHFnHoUHCIikamr4CAVXD62O1usdiUiInWr7oIjQz/duu64iEhk6io4rLGFNDrGISISpboKjnhjhibL6hiHiEiE6io4Eg1pmsmqxyEiEqFpueb4dEk2tZCwLN39uu64iEhU6qrHEW8MzleV69P5qkREolJXwWGp4HxVOV3MSUQkMnUVHAOnVi/0KzhERKJSZ8HRDEChTxdzEhGJSp0FR7CrynMKDhGRqNRXcITX5CjldE0OEZGoRBYcZtZoZk+Y2dNm9ryZfT5sX2Rmj5vZOjO7y8xSYXtDOL4ufHzhhJ807HGg646LiEQmyh5HFniXuy8GlgBnmdly4IvAl939SGAPcHk4/eXAnrD9y+F0ExMGRyzfN+XiRURkdOMKDjO7ysxmWeDbZvaUmZ051jweGPjonwxvDrwL+EHYfhvwgXB4ZThO+PgZZmYTeC1DwVHQ7zhERKIy3h7HZe7eBZwJzAE+Ctz4RjOZWdzM1gLbgYeAPwAd7j5wTpDNwCHh8CHAJoDw8U5g7jjrC6SGrjvursvHiohEYbzBMfDJ/xzgu+7+fFnbPrl70d2XAAuAk4C3TKrK8kLMrjSzNWa2ZseOHcMfTAZfx23yLL05XZNDRCQK4w2OJ83sZwTB8aCZtQCl8T6Ju3cAjwAnA61mNnCOrAXAlnB4C3AoQPj4bGDXKMu62d2Xufuy9vb2Ea8mTiHWSLPpKoAiIlEZb3BcDlwHnOjuvQTHKy4dawYzazez1nC4CXgP8CJBgJwXTnYxcG84fF84Tvj4L3wS+5uKiSaaybJXwSEiEonxnh33ZGCtu/eY2UeApcBX32Ceg4DbzCxOEFB3u/v9ZvYCsNrMbgB+D3w7nP7bwHfNbB2wG7hggq8FgFIyrR6HiEiExhsc3wAWm9li4G+AW4DbgdP3NYO7PwO8bZT29QTHO0a29wN/Ps569smTzbomh4hIhMa7q6oQ7jZaCfyru38daImurClIpknruuMiIpEZb3DsNbO/I/ga7gNmFiM4zjHzNKSDy8fmFBwiIlEYb3B8mOCX4Je5+2sE34b6UmRVTUG8IU2aLN1ZfR1XRCQK4wqOMCzuAGab2blAv7vfHmllkxRvbKFZu6pERCIz3lOOnA88QXDw+nzgcTM7b+y5qiPekKHZsvpWlYhIRMb7rarPEfyGYzsEv9EAfs7QOadmDEulSVu/vlUlIhKR8R7jiA2ERmjXBOadXqk0TWTp7s9XuxIRkbo03h7HT83sQeDOcPzDwI+jKWmKUs3EcHL9OkOuiEgUxhUc7v5pM/sQcErYdLO73xNdWVOQygBQ6NfFnEREojDeHgfu/kPghxHWUhnhqdWLugqgiEgkxgwOM9tLcPGl1z1EcK2mWZFUNRXhqdVdwSEiEokxg8PdZ+ZpRcYS7qryrI5xiIhEYWZ+M2oqUkGPg7yCQ0QkCnUYHOF1x/N9unysiEgE6jA4gl1Vjd5Hf37cFykUEZFxqr/gCA+ON5uuySEiEoX6C45wV1UzugqgiEgU6jY40roKoIhIJOovOGJxivEGmnWiQxGRSNRfcAClZIa0dlWJiESiLoMDnVpdRCQydRocGTL0KThERCJQl8ERa2zRrioRkYjUZ3A0tJC2Pl13XEQkAnUZHNaQpsWydGeL1S5FRKTu1GVwkGohY9pVJSIShciCw8wONbNHzOwFM3vezK4K29vM7CEzeyW8nxO2m5l9zczWmdkzZrZ00k/eEHwdVwfHRUQqL8oeRwH4G3c/GlgOfMLMjgauAx5296OAh8NxgLOBo8LblcA3Jv3MqQxN9NHdn59C+SIiMprIgsPdt7r7U+HwXuBF4BBgJXBbONltwAfC4ZXA7R74LdBqZgdN6slTaeKUyGd7p/ISRERkFNNyjMPMFgJvAx4H5rv71vCh14D54fAhwKay2TaHbRPXEFy4sNi/d1Kzi4jIvkUeHGaWAX4IXO3uXeWPeXClpQldbcnMrjSzNWa2ZseOHaNPNHj5WAWHiEilRRocZpYkCI073P1HYfO2gV1Q4f32sH0LcGjZ7AvCtmHc/WZ3X+buy9rb20d/4vAMuZbrrsCrEBGRclF+q8qAbwMvuvu/lD10H3BxOHwxcG9Z+0Xht6uWA51lu7QmpiHocZiuOy4iUnGJCJd9CvBR4FkzWxu2fRa4EbjbzC4HNgLnh4/9GDgHWAf0ApdO+plTwTGOxlIf2UKRhkR80osSEZHhIgsOd/8VYPt4+IxRpnfgExV58rDHEZyvSsEhIlJJdfrL8fAqgDpflYhIxdVpcAz1OPZm9SNAEZFKqvvg6OpTj0NEpJLqMzgSKUqxFBnrp7NPPQ4RkUqqz+AAPJUmTR9dCg4RkYqq2+Cwhhaa1eMQEam4Og6ODBkUHCIilVa/wZHKMDueVXCIiFRY3QYHDRlmxfrpUHCIiFRU/QZHKkPG1OMQEam0ug6OZvoUHCIiFVa/wdGQodn1dVwRkUqr3+BIZWgo9dHZm6t2JSIidaV+g6MhQ5wiff29BCfeFRGRSqjf4AjPV9VU6qM7q/NViYhUSt0HR9p0gFxEpJLqNzjCiznp1+MiIpVVv8HRNAeAVutWcIiIVFD9Bke6HYC5dOkruSIiFVS/wdE8D4C51qUeh4hIBdVxcLThGG0KDhGRiqrf4IjFobmNebaXjl4Fh4hIpdRvcADWPI8D43vV4xARqaC6Dg7S85gXU3CIiFRS3QeHDo6LiFRWfQdH8zxavVNfxxURqaDIgsPMbjWz7Wb2XFlbm5k9ZGavhPdzwnYzs6+Z2Toze8bMllakiHQ7mdJeunr6K7I4ERGJtsfx78BZI9quAx5296OAh8NxgLOBo8LblcA3KlJBOvgtR3bvDkolnSFXRKQSIgsOd38U2D2ieSVwWzh8G/CBsvbbPfBboNXMDppyEc1zAWgpdrCzJzvlxYmIyPQf45jv7lvD4deA+eHwIcCmsuk2h21TE552pM32snlP35QXJyIiVTw47sHVlSa8/8jMrjSzNWa2ZseOHWNPHO6qmkengkNEpEKmOzi2DeyCCu+3h+1bgEPLplsQtr2Ou9/s7svcfVl7e/vYzzasx9E7tcpFRASY/uC4D7g4HL4YuLes/aLw21XLgc6yXVqT1zQHMA5OdrNFPQ4RkYpIRLVgM7sT+FNgnpltBv4BuBG428wuBzYC54eT/xg4B1gH9AKXVqSI8HxVhxV7+LWCQ0SkIiILDndftY+HzhhlWgc+EUkh6Xbm9/ZoV5WISIXU9y/HAZrnMc+62NLRR5BPIiIyFfUfHOl5zC7toT9fYldPrtrViIjUvPoPjvY3M6tvM2n69JVcEZEKqP/gWHAS5iUWx/6g4xwiIhWwHwTHMgCW2iv6Sq6ISAXUf3A0tUL7Wzk5tY5ntnRWuxoRkZpX/8EBcOiJvM1e4bH/2ka+WKp2NSIiNW0/CY6301zqpj27id+9OvKEvSIiMhH7TXAAvD3xCg+/tP0NJhYRkbHsH8Ex90jIzOfP08/w8Ivb9ENAEZEp2D+CwwyWXsSS/scp7N7AK9u7q12RiEjN2j+CA+CES8FiXJz4Od9//L+rXY2ISM3af4Jj9iHYW8/lL5KPcv+T6+nOFqpdkYhITdp/ggPg7R8jXeri0uLd3PP7Ua8TJSIib2D/Co43nYwv+Qh/lbifXz/6M/2mQ0RkEvav4ADsvf9Mvqmdz3R/iR/+/FfVLkdEpObsd8FBUysNq77LvEQvZ/76L9j99APVrkhEpKbsf8EB2GFvp+vCn9JBC233/AWF2z4Az9wNPTurXZqIyIwX2aVjZ7qDjziWB//sQVb/xxf5+Mb7aX31EcDg4CWw4ERofzPMezO0HQ7peZBoqHbJIiIzwn4bHADvXXwYpdjf8/bV5/C25Eb+9ojNLM4+SXzt9yE34keCqZYgQNrfDPOPgfnHwqEnwewF1SleRKRK9uvgADj7uIP4kwNP5+/veY4/e/5NtDSczrnHH8j7F8GSpu009WyC3l3Qswu6X4PtL8ErD4EXgwW0HRGER9McaG4L7gdumQPhoMWQaa/uixQRqSCr5fM2LVu2zNesWVORZbk7T27cw/d+u5GHXthGT66IGRx1QIbjF7Sy+NBWFi+YzVEHtNAUK8D2F2Hj/4ONv4bu7dC3Z+g2ECoD4g2QbIREI6Qy0HooNM+FRFOwCywZ3ieaIJEC9+A0KY2tEItDvi+YpnF2eGsdGm6YBbH98lCViEySmT3p7ssmPb+C4/X680WeeHU3azd18PSmDtZu6mBXTw4ItueHtDZx5AEZFsxp4oCWRg5ra2bhvDSL5qWZ3ZiA7N4gQDo3wR/XQs92KGSh0A/9ndDx39DXEbb1Bff5vtcHzrhYEB6pNMST4S0V3KcyQUCZQTEfPE8xB6UitBwIbYuCMIvFweIQS4S3eHgLx618PB68vv7OYNmzDoaWg4LnLObC58iGry07oi0X3JcKQY8sfQCk26GhJQjOpjnB8svl+4PdhvFkEMDxFHgpeE0jpxWRcVFwRBAcI7k7Wzr6eHZzJ69s72ZdeNva2cee3vywadvSKd40t5l5mQbamlO0ppO0NaeY05yitTlJWzpFa3OKOc1JWptTxGM2NHOxEISLWbBx7O8MNvLJpiBY+jv3fct1BxvkYi685YMN/MA3xRKpMFBSQRB0bYGOjcHzzBQWD8LDi8HrLuaC9bEvjbMh2QxYsM6ChYwYZmgYwsfGMzxiWRYLQq710CDABsIWD9d7Pqi5VBi6DbwOLwW1ptuD9yq7dyprKXjOYaMlKJWC97ihJTge1xDeko1lHwjKbmawd1vwAae5DTLzg/oSqaDmnp1BrYW+ILzzvZDtGlrvxfBvrXlu8DxmwTqyWLjeYmGblY3HhqYbNk1sxHThfakYrMOGWcEHi1xvcN/cBrHk6PMMvGdjPlY23LsbujYH72WyKez9NwXrrZgP/v7yfcE6S2WCD4MdG4MPQ/Hk8L0AzW2QTAfvh5eC98lLQ3Xs2RDMn2gcen9SmfA+XfZ3N4pSKXwv+oJlNc0J1n/3tqDexln7/gKPe7B96N0dzNPQgs06aErBsd8f4xgPM2PBnGYWzGnm7BGPZQtFNu3uZf2OHjbs6uHVnT1s3NXLpt29PL2pg47ePLl9/ELdDGY1JpnTnGROeihcZjUmmdWYINOYoKUxSUtjgUxDEy2Ns0g3LSQ9O0G6IUG6IU5DYgqfut2H/jkHN3jFoQ3gYHtx+EaxIQMNs6F3J3T9EfZuDdoTjUEwJRrK7hvC0Cq7j8WDDVb3dujZAbme4B+0O9yQlfd8muYE/1zF/FAoWjx4vr7dwT/SwIbUKRv2MYbD6cYzPDCPl2Dva7Du4aCWgVAwG7FRjgcbtYEemsWDaba9ELzWptZgQ8EYG4nxGLmRsXjQm8t2B8GU75na8kcTTwX3xdzAk/K6EJNJsuEb/mEf6L1snYcSTeGHqrLp4g1Dx1djCSjlg7Do2xMMV7Ja9Tii5e705Irs6cnR0Ztnd2+Ojt4cu3ty7OnNDw539ObD+xx7+wt05wqM561Jxo3mVILmVJyGRIyGRJyGZGxoOBELxwcej9GQLBsOp0/GY6TiMZKJ4D6VsGFtcTPiMSNmRiwGcTNiMSMRMxLxWHAfDifjRiIW3NtYn6IkOqVi8CmzkB3eCyqW9YYy84ONTO/uILR7dgShGIsHPYnG2UOfwpPNwYbNPdhgDYRj357geQbCdSB4h42XhsZf1+Zl4yOmiyWCT9fZruB1JJuC+77dQz05yp+LoWWMfN7y8cFhgtc48M3IfO9QDyPfN/ThJ9kUrLPs3mDX7JxFQVsxP9Tj79sz9EFmZC+H8APa7AUwZ2HwGnLdYch3DQ0P7G0YVDacaAyeM5UOQqTrj8EHkJaDguVlO6G/K6ijvyPooQx88Br80k5bsJxsF3bSFfXT4zCzs4CvAnHgFne/scolTZmZkWlIkGlIcGjb+OcrlZyeXIG9/cGtO5unq79Ab7ZIT65AT7ZAb65Id7ZAbzicK5bI5ktkC0WyhRJ9+SIdfbmwbag9my/RXyiOK5imKmaQiMVIxG1wt1yp5JQ8eCzTmCAZjw2rZWDaZCxGPBYMl/8/xcxIxoNgGwiteBhcA+Fm4V4qMxu8j8cIl2WDQWgWhCBAX75IseThcsPlh8slXE7MjJhBLHyeeIzw+cL28D6D8QooAAAJSUlEQVQYD5ZfPj4wjQ22DZ9n8DliYMN2tU1FglH/1TsB9gBGc/IQ5s46nJI7uUKJTEPwvpQKTinvlLxAyfOD7108VqQhESMZbyaZSA9+4EjGY+H6Rh8aZrQrpjT3jAkOM4sDXwfeA2wGfmdm97n7C9WtrDpiMQt3UyUjWb67Uyh5GCRF8sVgg5ErlsgVSuSLQ8O5YolSySmWnJIHG46B4ULRKZRK5IvB4/liiULJKYT3QZtTDKexsg1lsQTd2TyFUpAahuE4pZKTLznFoofLGNrV5zD4PLlCid5csLEfmK5QdIrug0Hk+OAH26H6B17LQIg5DjQl48RiFtRedPLh8gbqk4l7fYAH7/PAYYjB4bJpKA/XEfPCQMi+fl5gMHBHW+ZAKJfPS9k0I+el7HljI+pncPnBePm8vO71Do07kCuUKLmTSgz16If1M0YE7vDHgnt36OrP09mXJxWP0ZyK05xKkIwP7QkY+BCVjMeImdFfKJIrlEjGpx7oMyY4gJOAde6+HsDMVgMrgf0yOKJmZZ/aMw0z6c9g5vIwNAfCp1QKhovu4Z6P4Y97ODzyvlQ2PnKZAyE3MD5denNFdnZnw55bjN5cgXyxFIb8UO9sYHzgw0K+WBoM8VyxRL7gQ2EdrrNguLytPNBHb4eydTRiXgjW/WjLZGDdDraFzxHMFn4wGX2Zvo95gWHv4bB5S+CUgkNeI+Zl2PjQe9mQiGNAd7YwuN4GjfzeQ/lw2d+DAy2NCeY0p8gWSuzsztGb6x38sFYKP0yVPPjgViiWaErFScVjFfkgNJO2GIcAm8rGNwNvr1ItIq8T7OKCeGX2H4lUjf391OavuV+OmdmVZrbGzNbs2LGj2uWIiOx3ZlJwbAEOLRtfELYN4+43u/syd1/W3q5TeYiITLeZFBy/A44ys0VmlgIuAO6rck0iIjLCjDnG4e4FM/tr4EGCr+Pe6u7PV7ksEREZYcYEB4C7/xj4cbXrEBGRfZtJu6pERKQGKDhERGRCFBwiIjIhCg4REZmQmj47rpntBV6udh3jMA/YWe0ixkF1Vk4t1Aiqs9Jqpc43u3vLZGeeUd+qmoSXp3Jq4OliZmtUZ+XUQp21UCOozkqrpTqnMr92VYmIyIQoOEREZEJqPThurnYB46Q6K6sW6qyFGkF1Vtp+UWdNHxwXEZHpV+s9DhERmWY1GxxmdpaZvWxm68zsumrXA2Bmh5rZI2b2gpk9b2ZXhe3Xm9kWM1sb3s6ZAbVuMLNnw3rWhG1tZvaQmb0S3s+pco1vLltna82sy8yungnr08xuNbPtZvZcWduo688CXwv/Vp8xs6VVrvNLZvZSWMs9ZtYati80s76y9frNKte5z/fZzP4uXJ8vm9l7q1znXWU1bjCztWF7VdbnGNuhyv19BpdurK0bwdlz/wAcDqSAp4GjZ0BdBwFLw+EW4L+Ao4HrgWurXd+IWjcA80a03QRcFw5fB3yx2nWOeM9fA940E9YncBqwFHjujdYfcA7wE4LLRy8HHq9ynWcCiXD4i2V1Liyfbgasz1Hf5/B/6mmgAVgUbgvi1apzxOP/C/if1VyfY2yHKvb3Was9jsHrk7t7Dhi4PnlVuftWd38qHN4LvEhwSdxasRK4LRy+DfhAFWsZ6QzgD+6+sdqFALj7o8DuEc37Wn8rgds98Fug1cwOqlad7v4zdy+Eo78luGhaVe1jfe7LSmC1u2fd/VVgHcE2IXJj1WlmBpwP3DkdtezLGNuhiv191mpwjHZ98hm1gTazhcDbgMfDpr8Ou4G3VnsXUMiBn5nZk2Z2Zdg23923hsOvAfOrU9qoLmD4P+RMW5+w7/U3k/9eLyP4tDlgkZn93sz+08xOrVZRZUZ7n2fq+jwV2Obur5S1VXV9jtgOVezvs1aDY0YzswzwQ+Bqd+8CvgEcASwBthJ0Z6vtne6+FDgb+ISZnVb+oAd92BnxlTsLrgj5fuA/wqaZuD6HmUnrb1/M7HNAAbgjbNoKHObubwOuAb5vZrOqVR818D6PsIrhH26quj5H2Q4NmurfZ60Gx7iuT14NZpYkeLPucPcfAbj7NncvunsJ+BbT1K0ei7tvCe+3A/cQ1LRtoIsa3m+vXoXDnA085e7bYGauz9C+1t+M+3s1s0uAc4ELw40I4a6fXeHwkwTHDv6kWjWO8T7PxPWZAP4MuGugrZrrc7TtEBX8+6zV4JiR1ycP93F+G3jR3f+lrL18f+EHgedGzjudzCxtZi0DwwQHS58jWIcXh5NdDNxbnQpfZ9gnuZm2Psvsa/3dB1wUfntlOdBZtstg2pnZWcDfAu93996y9nYzi4fDhwNHAeurU+WY7/N9wAVm1mBmiwjqfGK66xvh3cBL7r55oKFa63Nf2yEq+fc53Uf8K/jNgXMIvi3wB+Bz1a4nrOmdBN2/Z4C14e0c4LvAs2H7fcBBVa7zcIJvpTwNPD+w/oC5wMPAK8DPgbYZsE7TwC5gdllb1dcnQZBtBfIE+4Qv39f6I/i2ytfDv9VngWVVrnMdwT7tgb/Rb4bTfij8e1gLPAW8r8p17vN9Bj4Xrs+XgbOrWWfY/u/AX42Ytirrc4ztUMX+PvXLcRERmZBa3VUlIiJVouAQEZEJUXCIiMiEKDhERGRCFBwiIjIhCg6RMZhZ0YafobdiZ2IOz546U36DIjJuiWoXIDLD9bn7kmoXITKTqMchMgnhdRdusuCaJk+Y2ZFh+0Iz+0V4Yr6HzeywsH2+Bde+eDq8vSNcVNzMvhVeN+FnZtZUtRclMk4KDpGxNY3YVfXhssc63f044F+Br4Rt/xu4zd2PJzh54NfC9q8B/+nuiwmu5/B82H4U8HV3PwboIPi1sciMpl+Oi4zBzLrdPTNK+wbgXe6+Pjyh3GvuPtfMdhKcGiMftm9193lmtgNY4O7ZsmUsBB5y96PC8c8ASXe/IfpXJjJ56nGITJ7vY3gismXDRXTcUWqAgkNk8j5cdv+bcPjXBGdrBrgQeCwcfhj4GICZxc1s9nQVKVJp+nQjMrYmM1tbNv5Tdx/4Su4cM3uGoNewKmz7JPAdM/s0sAO4NGy/CrjZzC4n6Fl8jOAsqyI1R8c4RCYhPMaxzN13VrsWkemmXVUiIjIh6nGIiMiEqMchIiITouAQEZEJUXCIiMiEKDhERGRCFBwiIjIhCg4REZmQ/w8fCCVqyzyxbQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history2(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
